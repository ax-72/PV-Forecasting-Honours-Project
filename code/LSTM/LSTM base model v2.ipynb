{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits to Elissaios Sarmas for the model training and transfer learning code, which was adapted for use on this dataset. Code can be found here: https://github.com/ElissaiosSarmas/Transfer-learning-strategies-for-solar-power-forecasting-under-data-scarcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -r ./LSTM/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use a dataset obtained from Kaggle (credits to Afroz) that has 8760 entries and contains hourly PV output to train the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError, RootMeanSquaredError\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow import keras\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from hyperopt import fmin, tpe, hp, partial, Trials, STATUS_OK, STATUS_FAIL, space_eval\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold, cross_val_score \n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, zero_one_loss,mean_absolute_error,r2_score\n",
    "pd.options.mode.chained_assignment = None\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/work/Honours code/Datasets/Kaggle-Solar-PV-data/Solar Power Plant Data.csv\"\n",
    "\n",
    "p0 = pd.read_csv(path, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0_copy = p0.copy()\n",
    "p0_copy['timestamp'] = pd.to_datetime(p0['Date-Hour(NMT)'], format='%d.%m.%Y-%H:%M')\n",
    "\n",
    "p0_copy.drop(['Date-Hour(NMT)'], axis=1, inplace=True)\n",
    "\n",
    "timestamp = p0_copy.pop('timestamp')\n",
    "p0_copy.insert(0, 'timestamp', timestamp)\n",
    "p0_copy['hour'] = pd.to_datetime(p0_copy['timestamp']).dt.hour\n",
    "p0_copy['month'] = pd.to_datetime(p0_copy['timestamp']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>AirPressure</th>\n",
       "      <th>Radiation</th>\n",
       "      <th>AirTemperature</th>\n",
       "      <th>RelativeAirHumidity</th>\n",
       "      <th>SystemProduction</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1003.8</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1003.5</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1003.4</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1003.3</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1003.1</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  WindSpeed  Sunshine  AirPressure  Radiation  \\\n",
       "0 2017-01-01 00:00:00        0.6         0       1003.8       -7.4   \n",
       "1 2017-01-01 01:00:00        1.7         0       1003.5       -7.4   \n",
       "2 2017-01-01 02:00:00        0.6         0       1003.4       -6.7   \n",
       "3 2017-01-01 03:00:00        2.4         0       1003.3       -7.2   \n",
       "4 2017-01-01 04:00:00        4.0         0       1003.1       -6.3   \n",
       "\n",
       "   AirTemperature  RelativeAirHumidity  SystemProduction  hour  month  \n",
       "0             0.1                   97               0.0     0      1  \n",
       "1            -0.2                   98               0.0     1      1  \n",
       "2            -1.2                   99               0.0     2      1  \n",
       "3            -1.3                   99               0.0     3      1  \n",
       "4             3.6                   67               0.0     4      1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix = p0_copy.corr()\n",
    "# Plot the correlation matrix\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dataset = 8760\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform One-Hot-Encoding for Months and Sin-Cos Similarities for Hours\n",
    "data = p0_copy\n",
    "data['timestamp'] = pd.to_numeric(data['timestamp'])\n",
    "data = pd.get_dummies(data, columns=['month'])\n",
    "data.loc[:,'sin_hour'] = np.sin(2*np.pi*data['timestamp']/24)\n",
    "data.loc[:,'cos_hour'] = np.cos(2*np.pi*data['timestamp']/24)\n",
    "\n",
    "print(\"Total Dataset =\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shaping data for LSTM input\n",
    "def split_sequences(sequences, n_steps, n_outputs, only_production, validation_split):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern \n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix + n_outputs > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        if only_production==True:\n",
    "            seq_x, seq_y = sequences[i:end_ix, -1], sequences[end_ix:(end_ix+n_outputs), -1]\n",
    "        else:\n",
    "            seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:(end_ix+n_outputs), -1]\n",
    "            \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=validation_split, random_state=42)\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_shapes(x, y, lag_, n_features_, num_of_outputs_, only_production, validation_split):\n",
    "    unique_shapes = []\n",
    "    for k in range(len(x)):\n",
    "        if only_production==True:\n",
    "            if (x[k].shape == (lag,)) & (y[k].shape == (num_of_outputs_,)):\n",
    "                unique_shapes.append(k)\n",
    "        else:\n",
    "            if (x[k].shape == (lag_, n_features_)) & (y[k].shape == (num_of_outputs_,)):\n",
    "                unique_shapes.append(k)       \n",
    "    x = x[unique_shapes]\n",
    "    y = y[unique_shapes]\n",
    "    x = np.stack(x)\n",
    "    y = np.stack(y)\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=validation_split, random_state=42)\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns that you want to use as features\n",
    "cols = [\n",
    "    \"timestamp\",\n",
    "    \"WindSpeed\",\n",
    "    \"Sunshine\",\n",
    "    \"AirPressure\",\n",
    "    \"Radiation\",\n",
    "    \"AirTemperature\",\n",
    "    \"RelativeAirHumidity\",\n",
    "    \"sin_hour\",\n",
    "    \"cos_hour\",\n",
    "    \"SystemProduction\",\n",
    "    ]\n",
    "# Set to True if using only the production, else to False\n",
    "only_production = False\n",
    "# Splitting factor for training set and test set\n",
    "split = 0.4\n",
    "\n",
    "# Select the lag variable, the number of features (must be same with cols selected) and the horizon\n",
    "lag = 5\n",
    "n_features = len(cols)\n",
    "num_of_outputs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data seperately\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "if only_production == True:\n",
    "    data_ = data_['SystemProduction']\n",
    "    train = data_.iloc[:int(len(data_)*split_),]\n",
    "    test = data_.iloc[int(len(data_)*split_):,]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train = scaler.fit_transform(train.values.reshape(-1, 1))\n",
    "    test = scaler.fit_transform(test.values.reshape(-1, 1))\n",
    "else:\n",
    "    data = data[cols]\n",
    "    train = data.iloc[:int(len(data)*split),:]\n",
    "    test = data.iloc[int(len(data)*split):,]\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train = scaler.fit_transform(train)\n",
    "    test = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Train / Test = (1259, 5, 10) (1259, 1) (1890, 5, 10) (1890, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create the input for LSTM: x(batch_size, lag, features), y(batch_size,)\n",
    "\n",
    "x_train, x_val, y_train, y_val = split_sequences(train, n_steps=lag, n_outputs=num_of_outputs, only_production=only_production, validation_split=split)\n",
    "x_test, x_val, y_test, y_val = split_sequences(test, n_steps=lag, n_outputs=num_of_outputs, only_production=only_production, validation_split=split)\n",
    "\n",
    "x_train, x_val, y_train, y_val = unique_shapes(x_train, y_train, lag, n_features, num_of_outputs, only_production=only_production, validation_split=split)\n",
    "x_test, x_val, y_test, y_val = unique_shapes(x_test, y_test, lag, n_features, num_of_outputs, only_production=only_production, validation_split=split)\n",
    "\n",
    "# Reshape for only_production case\n",
    "if only_production:\n",
    "    x_train = x_train.reshape((x_train.shape[0], lag, 1))\n",
    "    x_test = x_test.reshape((x_test.shape[0], lag, 1))\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2])\n",
    "# Print the shapes\n",
    "print(\"Size of Train / Test =\", x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_error(actual, predicted):\n",
    "    res = np.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs(percentage_error(np.asarray(y_true), np.asarray(y_pred))))\n",
    "\n",
    "def createModel():\n",
    "\n",
    "    # LSTM Model Architecture\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.002, clipvalue=0.5)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(32,\n",
    "                                 activation=\"relu\",\n",
    "                                 return_sequences=True),\n",
    "                                input_shape=(x_train.shape[1], x_train.shape[2]), name = 'bidirectional_1'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Bidirectional(LSTM(128,activation=\"relu\",return_sequences=True), name = 'bidirectional_2'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Bidirectional(LSTM(256,activation=\"relu\",return_sequences=False), name = 'bidirectional_3'))\n",
    "    model.add(Dense(1, name='output_layer'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "    # renaming weight handles to ensure uniqueness\n",
    "    # credits to Nour Alden\n",
    "    # from https://stackoverflow.com/questions/72776335/valueerror-unable-to-create-dataset-name-already-exists-when-using-modelcheck\n",
    "\n",
    "    for i in range(len(model.weights)):\n",
    "        model.weights[i]._handle_name = model.weights[i].name + \"_\" + str(i)\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.layers import TFSMLayer\n",
    "import h5py\n",
    "import os\n",
    "import time\n",
    "timestamp = int(time.time())\n",
    "true_values = []\n",
    "predicted_values = []\n",
    "#model_path = \"C:/work/Honours code/Transfer learning/LSTM/model/LSTM_base.h5\"\n",
    "model_path = \"LSTM_base.h5\"\n",
    "def fit_predict_stats(model):\n",
    "    # Early stopping property\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "    tb = TensorBoard(log_dir='logs')\n",
    "    logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "    history = model.fit(x_train, y_train, epochs=100, validation_split=0.14, batch_size=32, verbose=1, shuffle=True, callbacks=[tensorboard_callback, es]).history\n",
    "   \n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        \n",
    "    # Load the model\n",
    "        tf.debugging.set_log_device_placement(True)\n",
    "        model = load_model(model_path)\n",
    "    else:\n",
    "        # Model file does not exist, so save the model\n",
    "        \n",
    "        # Fit the model\n",
    "        model.save(model_path, overwrite=True)\n",
    "\n",
    "\n",
    "\n",
    "    # summarize history for MAE and MSE\n",
    "    # plt.plot(history['loss'])\n",
    "    # plt.plot(history['val_loss'])\n",
    "    # plt.title('model loss')\n",
    "    # plt.ylabel('Model MSE')\n",
    "    # plt.xlabel('epoch')\n",
    "    # plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.plot(history['mae'])\n",
    "    # plt.plot(history['val_mae'])\n",
    "    # plt.title('Model MAE')\n",
    "    # plt.ylabel('MAE')\n",
    "    # plt.xlabel('epoch')\n",
    "    # plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    # Metrics on scaled data\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    y_pred = model.predict(x_train)\n",
    "    rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "    mae = mean_absolute_error(y_train, y_pred)\n",
    "    # print('Train Scaled RMSE: {}'.format(rmse))\n",
    "    # print('Train Scaled MAE: {}'.format(mae))\n",
    "    # print('Train Scaled R2 Score: ', r2_score(y_train, y_pred)*100)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    # print('Test Scaled RMSE: {}'.format(rmse))\n",
    "    # print('Test Scaled MAE: {}'.format(mae))\n",
    "    # print('Test Scaled R2 Score: ',r2_score(y_test, y_pred)*100)\n",
    "\n",
    "\n",
    "    \n",
    "    # Metrics on original data\n",
    "    true = []\n",
    "    hat = []\n",
    "    range_ = [0]\n",
    "    # range_ = list(range(6))\n",
    "\n",
    "    for i,j in zip([[x_train,y_train],[x_test,y_test]],['Train','Test']):\n",
    "        # make a prediction\n",
    "        yhat = model.predict(i[0])\n",
    "        if yhat.shape == (yhat.shape[0],):\n",
    "            yhat = yhat.reshape((yhat.shape[0],1))  \n",
    "      \n",
    "        y_hat = []\n",
    "        for k in range(len(yhat)):\n",
    "            if k == 0:\n",
    "                for l in range_:\n",
    "                    y_hat.append(yhat[k,l])\n",
    "            else:\n",
    "                y_hat.append(yhat[k,-1])\n",
    "        \n",
    "        y_hat = np.stack(y_hat)\n",
    "        y_hat = y_hat.reshape((y_hat.shape[0],1))\n",
    "        \n",
    "        i[0] = i[0].reshape((i[0].shape[0],lag,n_features))\n",
    "        \n",
    "        x_hat = []\n",
    "        for k in range(len(i[0])):\n",
    "            if k == 0:\n",
    "                x_hat.append(i[0][k])\n",
    "            elif k!= 0:\n",
    "                x_hat.append(i[0][k][-1,:])\n",
    "        \n",
    "        x_hat = np.vstack(x_hat)\n",
    "        \n",
    "        initial_x_hat_shape = x_hat.shape[0]\n",
    "        initial_y_hat_shape = y_hat.shape[0]\n",
    "        \n",
    "        # print(x_hat.shape)\n",
    "        # print(y_hat.shape)\n",
    "        \n",
    "        if x_hat.shape[0]-y_hat.shape[0] != 0.0:\n",
    "            if x_hat.shape[0] > y_hat.shape[0]:\n",
    "                for k in range(x_hat.shape[0]-y_hat.shape[0]):\n",
    "                    y_hat = np.insert(y_hat, 0, y_hat[0,0], axis=0)\n",
    "                    added_values = True\n",
    "            elif x_hat.shape[0] < y_hat.shape[0]:\n",
    "                y_hat = y_hat[-int(x_hat.shape[0]-y_hat.shape[0]):,:]\n",
    "                added_values = False\n",
    "        \n",
    "        # print(x_hat.shape)\n",
    "        # print(y_hat.shape)\n",
    "        \n",
    "        # invert scaling for forecast\n",
    "        if only_production==True:\n",
    "            inv_yhat = np.concatenate((x_hat[:,:-1],y_hat), axis=1)\n",
    "            inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "        else:    \n",
    "            inv_yhat = np.concatenate((x_hat[:,:-1],y_hat), axis=1)\n",
    "            inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "            inv_yhat = inv_yhat[:,-1]\n",
    "            \n",
    "        # invert scaling for actual\n",
    "        y_true = []\n",
    "        for k in range(len(i[1])):\n",
    "            if k ==0:\n",
    "                for l in range_:\n",
    "                    y_true.append(i[1][k,l])\n",
    "            else:\n",
    "                y_true.append(i[1][k,-1])\n",
    "\n",
    "        y_true = np.stack(y_true)\n",
    "        y_true = y_true.reshape((y_true.shape[0],1))\n",
    "        print(y_true.shape)\n",
    "\n",
    "        initial_y_true_shape = y_true.shape[0]\n",
    "        \n",
    "        if x_hat.shape[0]-y_true.shape[0] != 0.0:\n",
    "            if x_hat.shape[0] > y_true.shape[0]:\n",
    "                for k in range(x_hat.shape[0]-y_true.shape[0]):\n",
    "                    y_true = np.insert(y_true, 0, y_true[0,0], axis=0)\n",
    "                    added_values = True\n",
    "            elif x_hat.shape[0] < y_true.shape[0]:\n",
    "                y_true = y_true[-int(x_hat.shape[0]-y_true.shape[0]):,:]\n",
    "                added_values = False\n",
    "                \n",
    "        if only_production==True:\n",
    "            inv_y = np.concatenate((x_hat[:,:-1],y_true), axis=1)\n",
    "            inv_y = scaler.inverse_transform(inv_y)\n",
    "        else:\n",
    "            inv_y = np.concatenate((x_hat[:,:-1],y_true), axis=1)\n",
    "            inv_y = scaler.inverse_transform(inv_y)\n",
    "            inv_y = inv_y[:,-1]\n",
    "        \n",
    "        true.append(inv_y)\n",
    "        hat.append(inv_yhat)\n",
    "\n",
    "        # true_values.append(true)\n",
    "        # predicted_values.append(hat)\n",
    "        \n",
    "        # calculate RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "        print('Test RMSE: %.3f' % rmse)\n",
    "        # calculate MAE\n",
    "        mae = mean_absolute_error(inv_y, inv_yhat)\n",
    "        print('Test MAE: %.3f' % mae)\n",
    "        # calculate R2\n",
    "        r2 = r2_score(inv_y, inv_yhat)\n",
    "        print('Test R2 Score: ',r2)\n",
    "        # Calculate MAPE\n",
    "        mape = mean_absolute_percentage_error(inv_y, inv_yhat)\n",
    "        print('MAPE', mape)\n",
    "        # Calculate MBE\n",
    "        mbe = np.mean(inv_yhat - inv_y)\n",
    "        print('Test MBE', mbe)\n",
    "        # Calculate nRMSE\n",
    "        nRMSE = rmse / np.mean(inv_y)\n",
    "        print('nRMSE', nRMSE)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)\n",
    "    r_square_list.append(r2)\n",
    "    mape_list.append(mape)\n",
    "    mbe_list.append(mbe)\n",
    "    nRMSE_list.append(nRMSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 112ms/step - loss: 0.0300 - mae: 0.1021 - val_loss: 0.0195 - val_mae: 0.0780\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0199 - mae: 0.0736 - val_loss: 0.0143 - val_mae: 0.0553\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0164 - mae: 0.0656 - val_loss: 0.0124 - val_mae: 0.0451\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0105 - mae: 0.0482 - val_loss: 0.0101 - val_mae: 0.0442\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0118 - mae: 0.0507 - val_loss: 0.0105 - val_mae: 0.0472\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0110 - mae: 0.0523 - val_loss: 0.0093 - val_mae: 0.0370\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0083 - mae: 0.0390 - val_loss: 0.0088 - val_mae: 0.0390\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0067 - mae: 0.0369 - val_loss: 0.0085 - val_mae: 0.0429\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0075 - mae: 0.0413 - val_loss: 0.0071 - val_mae: 0.0414\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0063 - mae: 0.0415 - val_loss: 0.0079 - val_mae: 0.0349\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0074 - mae: 0.0393 - val_loss: 0.0083 - val_mae: 0.0398\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0052 - mae: 0.0346 - val_loss: 0.0069 - val_mae: 0.0310\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0057 - mae: 0.0343 - val_loss: 0.0081 - val_mae: 0.0352\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0061 - mae: 0.0355 - val_loss: 0.0097 - val_mae: 0.0394\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0083 - mae: 0.0407 - val_loss: 0.0093 - val_mae: 0.0431\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0065 - mae: 0.0378 - val_loss: 0.0080 - val_mae: 0.0324\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0048 - mae: 0.0296 - val_loss: 0.0089 - val_mae: 0.0386\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0055 - mae: 0.0363 - val_loss: 0.0093 - val_mae: 0.0394\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0047 - mae: 0.0312 - val_loss: 0.0072 - val_mae: 0.0311\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0042 - mae: 0.0310 - val_loss: 0.0089 - val_mae: 0.0458\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0062 - mae: 0.0393 - val_loss: 0.0078 - val_mae: 0.0343\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0065 - mae: 0.0351 - val_loss: 0.0088 - val_mae: 0.0371\n",
      "Epoch 22: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 117ms/step - loss: 0.0282 - mae: 0.0977 - val_loss: 0.0231 - val_mae: 0.0765\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0189 - mae: 0.0735 - val_loss: 0.0151 - val_mae: 0.0540\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0154 - mae: 0.0607 - val_loss: 0.0125 - val_mae: 0.0467\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0122 - mae: 0.0532 - val_loss: 0.0160 - val_mae: 0.0534\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0161 - mae: 0.0561 - val_loss: 0.0153 - val_mae: 0.0620\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0100 - mae: 0.0484 - val_loss: 0.0090 - val_mae: 0.0421\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0111 - mae: 0.0489 - val_loss: 0.0106 - val_mae: 0.0501\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0079 - mae: 0.0436 - val_loss: 0.0118 - val_mae: 0.0548\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0085 - mae: 0.0460 - val_loss: 0.0093 - val_mae: 0.0512\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0071 - mae: 0.0439 - val_loss: 0.0081 - val_mae: 0.0352\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0062 - mae: 0.0358 - val_loss: 0.0088 - val_mae: 0.0387\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0065 - mae: 0.0379 - val_loss: 0.0083 - val_mae: 0.0412\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0074 - mae: 0.0423 - val_loss: 0.0094 - val_mae: 0.0373\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0074 - mae: 0.0401 - val_loss: 0.0081 - val_mae: 0.0392\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0059 - mae: 0.0378 - val_loss: 0.0092 - val_mae: 0.0378\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0066 - mae: 0.0379 - val_loss: 0.0084 - val_mae: 0.0364\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0049 - mae: 0.0308 - val_loss: 0.0080 - val_mae: 0.0332\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0060 - mae: 0.0369 - val_loss: 0.0089 - val_mae: 0.0416\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0046 - mae: 0.0358 - val_loss: 0.0082 - val_mae: 0.0380\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0062 - mae: 0.0353 - val_loss: 0.0079 - val_mae: 0.0320\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0054 - mae: 0.0337 - val_loss: 0.0086 - val_mae: 0.0362\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0069 - mae: 0.0380 - val_loss: 0.0081 - val_mae: 0.0377\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0053 - mae: 0.0305 - val_loss: 0.0085 - val_mae: 0.0379\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0059 - mae: 0.0342 - val_loss: 0.0084 - val_mae: 0.0341\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0049 - mae: 0.0315 - val_loss: 0.0077 - val_mae: 0.0331\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0054 - mae: 0.0326 - val_loss: 0.0088 - val_mae: 0.0338\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0043 - mae: 0.0296 - val_loss: 0.0072 - val_mae: 0.0279\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0056 - mae: 0.0315 - val_loss: 0.0109 - val_mae: 0.0405\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0055 - mae: 0.0356 - val_loss: 0.0088 - val_mae: 0.0390\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0041 - mae: 0.0306 - val_loss: 0.0076 - val_mae: 0.0306\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0045 - mae: 0.0311 - val_loss: 0.0075 - val_mae: 0.0287\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0041 - mae: 0.0302 - val_loss: 0.0091 - val_mae: 0.0363\n",
      "Epoch 33/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0037 - mae: 0.0263 - val_loss: 0.0094 - val_mae: 0.0333\n",
      "Epoch 34/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0031 - mae: 0.0258 - val_loss: 0.0107 - val_mae: 0.0424\n",
      "Epoch 35/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0062 - mae: 0.0346 - val_loss: 0.0087 - val_mae: 0.0372\n",
      "Epoch 36/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0040 - mae: 0.0294 - val_loss: 0.0079 - val_mae: 0.0325\n",
      "Epoch 37/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0037 - mae: 0.0294 - val_loss: 0.0081 - val_mae: 0.0300\n",
      "Epoch 37: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 120ms/step - loss: 0.0307 - mae: 0.1045 - val_loss: 0.0189 - val_mae: 0.0654\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0197 - mae: 0.0710 - val_loss: 0.0157 - val_mae: 0.0602\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0167 - mae: 0.0618 - val_loss: 0.0119 - val_mae: 0.0520\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0145 - mae: 0.0625 - val_loss: 0.0111 - val_mae: 0.0502\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0117 - mae: 0.0508 - val_loss: 0.0103 - val_mae: 0.0499\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0088 - mae: 0.0458 - val_loss: 0.0091 - val_mae: 0.0486\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0107 - mae: 0.0503 - val_loss: 0.0098 - val_mae: 0.0424\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0091 - mae: 0.0452 - val_loss: 0.0093 - val_mae: 0.0368\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0091 - mae: 0.0429 - val_loss: 0.0092 - val_mae: 0.0394\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0067 - mae: 0.0391 - val_loss: 0.0130 - val_mae: 0.0520\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0078 - mae: 0.0412 - val_loss: 0.0076 - val_mae: 0.0382\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0062 - mae: 0.0408 - val_loss: 0.0076 - val_mae: 0.0347\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0055 - mae: 0.0337 - val_loss: 0.0144 - val_mae: 0.0486\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0056 - mae: 0.0353 - val_loss: 0.0069 - val_mae: 0.0332\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0065 - mae: 0.0347 - val_loss: 0.0074 - val_mae: 0.0296\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0053 - mae: 0.0315 - val_loss: 0.0083 - val_mae: 0.0462\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0086 - mae: 0.0462 - val_loss: 0.0084 - val_mae: 0.0385\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0053 - mae: 0.0340 - val_loss: 0.0068 - val_mae: 0.0325\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0060 - mae: 0.0392 - val_loss: 0.0068 - val_mae: 0.0315\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0047 - mae: 0.0346 - val_loss: 0.0078 - val_mae: 0.0386\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.0050 - mae: 0.0338 - val_loss: 0.0070 - val_mae: 0.0306\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0040 - mae: 0.0299 - val_loss: 0.0084 - val_mae: 0.0346\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0045 - mae: 0.0288 - val_loss: 0.0085 - val_mae: 0.0321\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0037 - mae: 0.0293 - val_loss: 0.0090 - val_mae: 0.0438\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0038 - mae: 0.0289 - val_loss: 0.0078 - val_mae: 0.0323\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0031 - mae: 0.0246 - val_loss: 0.0081 - val_mae: 0.0345\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0039 - mae: 0.0284 - val_loss: 0.0077 - val_mae: 0.0312\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0038 - mae: 0.0281 - val_loss: 0.0079 - val_mae: 0.0319\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0027 - mae: 0.0252 - val_loss: 0.0073 - val_mae: 0.0312\n",
      "Epoch 29: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_23\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_23\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 140ms/step - loss: 0.0297 - mae: 0.0989 - val_loss: 0.0223 - val_mae: 0.1065\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0210 - mae: 0.0898 - val_loss: 0.0202 - val_mae: 0.0650\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0170 - mae: 0.0676 - val_loss: 0.0139 - val_mae: 0.0601\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0144 - mae: 0.0580 - val_loss: 0.0116 - val_mae: 0.0571\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0097 - mae: 0.0463 - val_loss: 0.0109 - val_mae: 0.0446\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0124 - mae: 0.0550 - val_loss: 0.0106 - val_mae: 0.0439\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0081 - mae: 0.0422 - val_loss: 0.0115 - val_mae: 0.0463\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0090 - mae: 0.0443 - val_loss: 0.0084 - val_mae: 0.0383\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0075 - mae: 0.0402 - val_loss: 0.0081 - val_mae: 0.0360\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0063 - mae: 0.0381 - val_loss: 0.0090 - val_mae: 0.0409\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0067 - mae: 0.0411 - val_loss: 0.0087 - val_mae: 0.0438\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0051 - mae: 0.0371 - val_loss: 0.0090 - val_mae: 0.0395\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0064 - mae: 0.0336 - val_loss: 0.0087 - val_mae: 0.0460\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0066 - mae: 0.0410 - val_loss: 0.0077 - val_mae: 0.0351\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0043 - mae: 0.0344 - val_loss: 0.0076 - val_mae: 0.0322\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0051 - mae: 0.0314 - val_loss: 0.0079 - val_mae: 0.0335\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0059 - mae: 0.0367 - val_loss: 0.0078 - val_mae: 0.0344\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0041 - mae: 0.0276 - val_loss: 0.0091 - val_mae: 0.0364\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0074 - mae: 0.0382 - val_loss: 0.0094 - val_mae: 0.0395\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0069 - mae: 0.0363 - val_loss: 0.0092 - val_mae: 0.0374\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 0.0057 - mae: 0.0339 - val_loss: 0.0077 - val_mae: 0.0331\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0045 - mae: 0.0315 - val_loss: 0.0115 - val_mae: 0.0443\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0063 - mae: 0.0362 - val_loss: 0.0110 - val_mae: 0.0508\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0049 - mae: 0.0354 - val_loss: 0.0077 - val_mae: 0.0322\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0041 - mae: 0.0284 - val_loss: 0.0071 - val_mae: 0.0307\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0048 - mae: 0.0331 - val_loss: 0.0072 - val_mae: 0.0307\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0054 - mae: 0.0329 - val_loss: 0.0076 - val_mae: 0.0309\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0043 - mae: 0.0295 - val_loss: 0.0083 - val_mae: 0.0344\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0039 - mae: 0.0294 - val_loss: 0.0076 - val_mae: 0.0328\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0041 - mae: 0.0269 - val_loss: 0.0096 - val_mae: 0.0426\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0035 - mae: 0.0283 - val_loss: 0.0075 - val_mae: 0.0305\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0042 - mae: 0.0276 - val_loss: 0.0076 - val_mae: 0.0309\n",
      "Epoch 33/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0035 - mae: 0.0261 - val_loss: 0.0091 - val_mae: 0.0364\n",
      "Epoch 34/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0044 - mae: 0.0304 - val_loss: 0.0097 - val_mae: 0.0368\n",
      "Epoch 35/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0039 - mae: 0.0273 - val_loss: 0.0094 - val_mae: 0.0397\n",
      "Epoch 35: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_24\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_24\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 149ms/step - loss: 0.0321 - mae: 0.1055 - val_loss: 0.0205 - val_mae: 0.0772\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0196 - mae: 0.0783 - val_loss: 0.0184 - val_mae: 0.0660\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0139 - mae: 0.0576 - val_loss: 0.0094 - val_mae: 0.0470\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 0.0161 - mae: 0.0664 - val_loss: 0.0185 - val_mae: 0.0712\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0147 - mae: 0.0598 - val_loss: 0.0178 - val_mae: 0.0732\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0111 - mae: 0.0588 - val_loss: 0.0097 - val_mae: 0.0444\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0080 - mae: 0.0442 - val_loss: 0.0088 - val_mae: 0.0390\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0074 - mae: 0.0389 - val_loss: 0.0086 - val_mae: 0.0402\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.0074 - mae: 0.0413 - val_loss: 0.0090 - val_mae: 0.0443\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0073 - mae: 0.0449 - val_loss: 0.0084 - val_mae: 0.0381\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0069 - mae: 0.0397 - val_loss: 0.0095 - val_mae: 0.0393\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0061 - mae: 0.0351 - val_loss: 0.0073 - val_mae: 0.0365\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 0.0063 - mae: 0.0361 - val_loss: 0.0126 - val_mae: 0.0512\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0133 - mae: 0.0519 - val_loss: 0.0089 - val_mae: 0.0427\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - loss: 0.0073 - mae: 0.0428 - val_loss: 0.0078 - val_mae: 0.0357\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0063 - mae: 0.0376 - val_loss: 0.0098 - val_mae: 0.0445\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0050 - mae: 0.0338 - val_loss: 0.0096 - val_mae: 0.0391\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.0050 - mae: 0.0330 - val_loss: 0.0075 - val_mae: 0.0356\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0052 - mae: 0.0336 - val_loss: 0.0076 - val_mae: 0.0333\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0050 - mae: 0.0306 - val_loss: 0.0097 - val_mae: 0.0434\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0063 - mae: 0.0386 - val_loss: 0.0115 - val_mae: 0.0475\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - loss: 0.0049 - mae: 0.0332 - val_loss: 0.0074 - val_mae: 0.0350\n",
      "Epoch 22: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_25\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_25\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 148ms/step - loss: 0.0352 - mae: 0.1093 - val_loss: 0.0203 - val_mae: 0.0743\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0281 - mae: 0.0832 - val_loss: 0.0207 - val_mae: 0.0718\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.0201 - mae: 0.0729 - val_loss: 0.0164 - val_mae: 0.0572\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0140 - mae: 0.0613 - val_loss: 0.0114 - val_mae: 0.0511\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0103 - mae: 0.0503 - val_loss: 0.0100 - val_mae: 0.0411\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0104 - mae: 0.0484 - val_loss: 0.0152 - val_mae: 0.0658\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0125 - mae: 0.0554 - val_loss: 0.0092 - val_mae: 0.0400\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0080 - mae: 0.0403 - val_loss: 0.0105 - val_mae: 0.0540\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0112 - mae: 0.0514 - val_loss: 0.0092 - val_mae: 0.0420\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0085 - mae: 0.0443 - val_loss: 0.0078 - val_mae: 0.0352\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0063 - mae: 0.0377 - val_loss: 0.0078 - val_mae: 0.0338\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0067 - mae: 0.0387 - val_loss: 0.0073 - val_mae: 0.0329\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0061 - mae: 0.0351 - val_loss: 0.0088 - val_mae: 0.0396\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.0054 - mae: 0.0335 - val_loss: 0.0109 - val_mae: 0.0444\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 0.0058 - mae: 0.0370 - val_loss: 0.0080 - val_mae: 0.0392\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0063 - mae: 0.0401 - val_loss: 0.0095 - val_mae: 0.0410\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0063 - mae: 0.0362 - val_loss: 0.0088 - val_mae: 0.0415\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0078 - mae: 0.0392 - val_loss: 0.0072 - val_mae: 0.0312\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 0.0051 - mae: 0.0316 - val_loss: 0.0084 - val_mae: 0.0331\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0072 - mae: 0.0376 - val_loss: 0.0070 - val_mae: 0.0395\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 0.0050 - mae: 0.0366 - val_loss: 0.0085 - val_mae: 0.0359\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0064 - mae: 0.0372 - val_loss: 0.0082 - val_mae: 0.0312\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0041 - mae: 0.0280 - val_loss: 0.0093 - val_mae: 0.0422\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0062 - mae: 0.0347 - val_loss: 0.0087 - val_mae: 0.0469\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0064 - mae: 0.0403 - val_loss: 0.0076 - val_mae: 0.0331\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 0.0044 - mae: 0.0314 - val_loss: 0.0077 - val_mae: 0.0303\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0040 - mae: 0.0284 - val_loss: 0.0158 - val_mae: 0.0646\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0047 - mae: 0.0358 - val_loss: 0.0082 - val_mae: 0.0341\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - loss: 0.0040 - mae: 0.0285 - val_loss: 0.0074 - val_mae: 0.0364\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0044 - mae: 0.0325 - val_loss: 0.0076 - val_mae: 0.0309\n",
      "Epoch 30: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_26\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_26\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 157ms/step - loss: 0.0314 - mae: 0.1012 - val_loss: 0.0201 - val_mae: 0.0695\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0213 - mae: 0.0771 - val_loss: 0.0174 - val_mae: 0.0621\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0147 - mae: 0.0646 - val_loss: 0.0146 - val_mae: 0.0494\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.0121 - mae: 0.0537 - val_loss: 0.0106 - val_mae: 0.0481\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.0121 - mae: 0.0537 - val_loss: 0.0109 - val_mae: 0.0474\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - loss: 0.0088 - mae: 0.0462 - val_loss: 0.0073 - val_mae: 0.0468\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 0.0082 - mae: 0.0460 - val_loss: 0.0083 - val_mae: 0.0378\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0082 - mae: 0.0428 - val_loss: 0.0076 - val_mae: 0.0334\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 0.0067 - mae: 0.0376 - val_loss: 0.0085 - val_mae: 0.0363\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.0079 - mae: 0.0417 - val_loss: 0.0080 - val_mae: 0.0344\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0065 - mae: 0.0357 - val_loss: 0.0098 - val_mae: 0.0412\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0064 - mae: 0.0374 - val_loss: 0.0075 - val_mae: 0.0339\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.0055 - mae: 0.0349 - val_loss: 0.0069 - val_mae: 0.0358\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0075 - mae: 0.0411 - val_loss: 0.0074 - val_mae: 0.0340\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - loss: 0.0058 - mae: 0.0354 - val_loss: 0.0070 - val_mae: 0.0339\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.0052 - mae: 0.0327 - val_loss: 0.0079 - val_mae: 0.0342\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0052 - mae: 0.0305 - val_loss: 0.0073 - val_mae: 0.0319\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0063 - mae: 0.0356 - val_loss: 0.0081 - val_mae: 0.0363\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0063 - mae: 0.0348 - val_loss: 0.0077 - val_mae: 0.0329\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0043 - mae: 0.0304 - val_loss: 0.0075 - val_mae: 0.0365\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0058 - mae: 0.0373 - val_loss: 0.0077 - val_mae: 0.0338\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0048 - mae: 0.0327 - val_loss: 0.0077 - val_mae: 0.0350\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 0.0050 - mae: 0.0332 - val_loss: 0.0065 - val_mae: 0.0299\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.0049 - mae: 0.0328 - val_loss: 0.0094 - val_mae: 0.0455\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.0057 - mae: 0.0361 - val_loss: 0.0101 - val_mae: 0.0422\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.0044 - mae: 0.0346 - val_loss: 0.0078 - val_mae: 0.0310\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.0042 - mae: 0.0286 - val_loss: 0.0080 - val_mae: 0.0359\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 0.0046 - mae: 0.0300 - val_loss: 0.0084 - val_mae: 0.0399\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.0037 - mae: 0.0298 - val_loss: 0.0077 - val_mae: 0.0337\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 0.0037 - mae: 0.0285 - val_loss: 0.0074 - val_mae: 0.0307\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0035 - mae: 0.0276 - val_loss: 0.0081 - val_mae: 0.0372\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 0.0033 - mae: 0.0266 - val_loss: 0.0083 - val_mae: 0.0319\n",
      "Epoch 33/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.0038 - mae: 0.0292 - val_loss: 0.0083 - val_mae: 0.0321\n",
      "Epoch 33: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_27\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_27\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 169ms/step - loss: 0.0291 - mae: 0.0984 - val_loss: 0.0209 - val_mae: 0.0767\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0247 - mae: 0.0874 - val_loss: 0.0162 - val_mae: 0.0606\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0142 - mae: 0.0554 - val_loss: 0.0173 - val_mae: 0.0539\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0133 - mae: 0.0542 - val_loss: 0.0133 - val_mae: 0.0614\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0104 - mae: 0.0532 - val_loss: 0.0099 - val_mae: 0.0477\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0095 - mae: 0.0479 - val_loss: 0.0091 - val_mae: 0.0437\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - loss: 0.0089 - mae: 0.0467 - val_loss: 0.0096 - val_mae: 0.0432\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0076 - mae: 0.0419 - val_loss: 0.0083 - val_mae: 0.0443\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.0084 - mae: 0.0443 - val_loss: 0.0087 - val_mae: 0.0388\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.0083 - mae: 0.0445 - val_loss: 0.0083 - val_mae: 0.0385\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.0062 - mae: 0.0407 - val_loss: 0.0092 - val_mae: 0.0457\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 0.0077 - mae: 0.0435 - val_loss: 0.0089 - val_mae: 0.0398\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 0.0056 - mae: 0.0355 - val_loss: 0.0080 - val_mae: 0.0379\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0066 - mae: 0.0379 - val_loss: 0.0079 - val_mae: 0.0341\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0060 - mae: 0.0377 - val_loss: 0.0088 - val_mae: 0.0416\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.0061 - mae: 0.0395 - val_loss: 0.0081 - val_mae: 0.0373\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 0.0062 - mae: 0.0385 - val_loss: 0.0080 - val_mae: 0.0356\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0065 - mae: 0.0376 - val_loss: 0.0083 - val_mae: 0.0333\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0042 - mae: 0.0286 - val_loss: 0.0079 - val_mae: 0.0360\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0054 - mae: 0.0348 - val_loss: 0.0080 - val_mae: 0.0340\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0039 - mae: 0.0286 - val_loss: 0.0084 - val_mae: 0.0336\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0064 - mae: 0.0356 - val_loss: 0.0074 - val_mae: 0.0331\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0049 - mae: 0.0320 - val_loss: 0.0080 - val_mae: 0.0312\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.0038 - mae: 0.0267 - val_loss: 0.0095 - val_mae: 0.0382\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0052 - mae: 0.0317 - val_loss: 0.0097 - val_mae: 0.0396\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - loss: 0.0051 - mae: 0.0336 - val_loss: 0.0080 - val_mae: 0.0302\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - loss: 0.0039 - mae: 0.0278 - val_loss: 0.0101 - val_mae: 0.0366\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0044 - mae: 0.0308 - val_loss: 0.0079 - val_mae: 0.0321\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 0.0044 - mae: 0.0305 - val_loss: 0.0078 - val_mae: 0.0345\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 0.0046 - mae: 0.0318 - val_loss: 0.0120 - val_mae: 0.0478\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.0064 - mae: 0.0365 - val_loss: 0.0106 - val_mae: 0.0435\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0037 - mae: 0.0283 - val_loss: 0.0085 - val_mae: 0.0377\n",
      "Epoch 32: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_28\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_28\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_37 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 152ms/step - loss: 0.0330 - mae: 0.1093 - val_loss: 0.0198 - val_mae: 0.0685\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0172 - mae: 0.0662 - val_loss: 0.0132 - val_mae: 0.0577\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.0129 - mae: 0.0556 - val_loss: 0.0138 - val_mae: 0.0575\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0091 - mae: 0.0446 - val_loss: 0.0121 - val_mae: 0.0516\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0110 - mae: 0.0558 - val_loss: 0.0098 - val_mae: 0.0402\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.0092 - mae: 0.0438 - val_loss: 0.0141 - val_mae: 0.0522\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.0102 - mae: 0.0484 - val_loss: 0.0091 - val_mae: 0.0448\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0079 - mae: 0.0430 - val_loss: 0.0099 - val_mae: 0.0426\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - loss: 0.0062 - mae: 0.0389 - val_loss: 0.0079 - val_mae: 0.0373\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0066 - mae: 0.0380 - val_loss: 0.0094 - val_mae: 0.0450\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.0081 - mae: 0.0436 - val_loss: 0.0084 - val_mae: 0.0369\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0068 - mae: 0.0397 - val_loss: 0.0080 - val_mae: 0.0314\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0051 - mae: 0.0317 - val_loss: 0.0079 - val_mae: 0.0352\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - loss: 0.0070 - mae: 0.0402 - val_loss: 0.0095 - val_mae: 0.0412\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.0063 - mae: 0.0395 - val_loss: 0.0098 - val_mae: 0.0394\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - loss: 0.0050 - mae: 0.0329 - val_loss: 0.0091 - val_mae: 0.0370\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.0051 - mae: 0.0317 - val_loss: 0.0108 - val_mae: 0.0445\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0045 - mae: 0.0311 - val_loss: 0.0081 - val_mae: 0.0366\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - loss: 0.0044 - mae: 0.0320 - val_loss: 0.0088 - val_mae: 0.0406\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0055 - mae: 0.0332 - val_loss: 0.0078 - val_mae: 0.0329\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0043 - mae: 0.0281 - val_loss: 0.0086 - val_mae: 0.0339\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.0057 - mae: 0.0331 - val_loss: 0.0081 - val_mae: 0.0416\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - loss: 0.0045 - mae: 0.0334 - val_loss: 0.0078 - val_mae: 0.0319\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 0.0040 - mae: 0.0277 - val_loss: 0.0078 - val_mae: 0.0357\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.0034 - mae: 0.0293 - val_loss: 0.0083 - val_mae: 0.0343\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0045 - mae: 0.0314 - val_loss: 0.0082 - val_mae: 0.0318\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.0029 - mae: 0.0243 - val_loss: 0.0078 - val_mae: 0.0294\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0048 - mae: 0.0301 - val_loss: 0.0116 - val_mae: 0.0427\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.0047 - mae: 0.0316 - val_loss: 0.0093 - val_mae: 0.0355\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.0040 - mae: 0.0300 - val_loss: 0.0092 - val_mae: 0.0402\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0037 - mae: 0.0282 - val_loss: 0.0090 - val_mae: 0.0343\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - loss: 0.0041 - mae: 0.0310 - val_loss: 0.0082 - val_mae: 0.0325\n",
      "Epoch 33/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - loss: 0.0027 - mae: 0.0248 - val_loss: 0.0087 - val_mae: 0.0358\n",
      "Epoch 34/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - loss: 0.0046 - mae: 0.0293 - val_loss: 0.0079 - val_mae: 0.0361\n",
      "Epoch 34: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_38 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_39 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 134ms/step - loss: 0.0321 - mae: 0.1009 - val_loss: 0.0221 - val_mae: 0.0676\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0181 - mae: 0.0673 - val_loss: 0.0148 - val_mae: 0.0633\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0151 - mae: 0.0619 - val_loss: 0.0135 - val_mae: 0.0547\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0123 - mae: 0.0594 - val_loss: 0.0106 - val_mae: 0.0430\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0088 - mae: 0.0414 - val_loss: 0.0081 - val_mae: 0.0378\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0083 - mae: 0.0447 - val_loss: 0.0087 - val_mae: 0.0435\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0101 - mae: 0.0487 - val_loss: 0.0099 - val_mae: 0.0432\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0104 - mae: 0.0456 - val_loss: 0.0091 - val_mae: 0.0398\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0068 - mae: 0.0395 - val_loss: 0.0083 - val_mae: 0.0425\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0055 - mae: 0.0361 - val_loss: 0.0093 - val_mae: 0.0425\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0100 - mae: 0.0461 - val_loss: 0.0103 - val_mae: 0.0508\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0071 - mae: 0.0471 - val_loss: 0.0078 - val_mae: 0.0431\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0056 - mae: 0.0381 - val_loss: 0.0071 - val_mae: 0.0342\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0045 - mae: 0.0318 - val_loss: 0.0094 - val_mae: 0.0433\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0072 - mae: 0.0396 - val_loss: 0.0098 - val_mae: 0.0443\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0067 - mae: 0.0400 - val_loss: 0.0120 - val_mae: 0.0465\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0084 - mae: 0.0419 - val_loss: 0.0080 - val_mae: 0.0377\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0052 - mae: 0.0333 - val_loss: 0.0072 - val_mae: 0.0316\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0054 - mae: 0.0337 - val_loss: 0.0076 - val_mae: 0.0333\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0037 - mae: 0.0290 - val_loss: 0.0070 - val_mae: 0.0304\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0045 - mae: 0.0289 - val_loss: 0.0073 - val_mae: 0.0317\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0043 - mae: 0.0288 - val_loss: 0.0075 - val_mae: 0.0330\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0040 - mae: 0.0294 - val_loss: 0.0098 - val_mae: 0.0382\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0037 - mae: 0.0282 - val_loss: 0.0086 - val_mae: 0.0343\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0032 - mae: 0.0260 - val_loss: 0.0074 - val_mae: 0.0342\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0036 - mae: 0.0299 - val_loss: 0.0083 - val_mae: 0.0323\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0031 - mae: 0.0246 - val_loss: 0.0073 - val_mae: 0.0348\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0033 - mae: 0.0273 - val_loss: 0.0082 - val_mae: 0.0394\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0034 - mae: 0.0279 - val_loss: 0.0076 - val_mae: 0.0296\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0033 - mae: 0.0248 - val_loss: 0.0090 - val_mae: 0.0343\n",
      "Epoch 30: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_30\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_30\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_40 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 127ms/step - loss: 0.0293 - mae: 0.0983 - val_loss: 0.0210 - val_mae: 0.0683\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0194 - mae: 0.0725 - val_loss: 0.0162 - val_mae: 0.0558\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0137 - mae: 0.0551 - val_loss: 0.0110 - val_mae: 0.0484\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0119 - mae: 0.0528 - val_loss: 0.0133 - val_mae: 0.0487\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0124 - mae: 0.0514 - val_loss: 0.0101 - val_mae: 0.0431\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0093 - mae: 0.0465 - val_loss: 0.0152 - val_mae: 0.0593\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0115 - mae: 0.0509 - val_loss: 0.0125 - val_mae: 0.0501\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0072 - mae: 0.0417 - val_loss: 0.0084 - val_mae: 0.0396\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0082 - mae: 0.0440 - val_loss: 0.0097 - val_mae: 0.0395\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0071 - mae: 0.0388 - val_loss: 0.0080 - val_mae: 0.0337\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0063 - mae: 0.0387 - val_loss: 0.0078 - val_mae: 0.0341\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0055 - mae: 0.0323 - val_loss: 0.0084 - val_mae: 0.0382\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0051 - mae: 0.0329 - val_loss: 0.0092 - val_mae: 0.0394\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0047 - mae: 0.0331 - val_loss: 0.0079 - val_mae: 0.0337\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0054 - mae: 0.0324 - val_loss: 0.0084 - val_mae: 0.0343\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0054 - mae: 0.0326 - val_loss: 0.0075 - val_mae: 0.0300\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0052 - mae: 0.0304 - val_loss: 0.0095 - val_mae: 0.0369\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0051 - mae: 0.0313 - val_loss: 0.0079 - val_mae: 0.0305\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0033 - mae: 0.0266 - val_loss: 0.0078 - val_mae: 0.0309\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0051 - mae: 0.0310 - val_loss: 0.0072 - val_mae: 0.0319\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0045 - mae: 0.0350 - val_loss: 0.0090 - val_mae: 0.0358\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0043 - mae: 0.0308 - val_loss: 0.0086 - val_mae: 0.0367\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0048 - mae: 0.0321 - val_loss: 0.0081 - val_mae: 0.0326\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0039 - mae: 0.0301 - val_loss: 0.0091 - val_mae: 0.0327\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0040 - mae: 0.0276 - val_loss: 0.0090 - val_mae: 0.0402\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0038 - mae: 0.0325 - val_loss: 0.0135 - val_mae: 0.0462\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0040 - mae: 0.0288 - val_loss: 0.0087 - val_mae: 0.0352\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0046 - mae: 0.0317 - val_loss: 0.0088 - val_mae: 0.0380\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0057 - mae: 0.0372 - val_loss: 0.0090 - val_mae: 0.0355\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0026 - mae: 0.0266 - val_loss: 0.0091 - val_mae: 0.0349\n",
      "Epoch 30: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_31\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_31\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_42 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_43 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 119ms/step - loss: 0.0355 - mae: 0.1129 - val_loss: 0.0200 - val_mae: 0.0674\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0212 - mae: 0.0731 - val_loss: 0.0174 - val_mae: 0.0596\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0173 - mae: 0.0603 - val_loss: 0.0110 - val_mae: 0.0467\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0121 - mae: 0.0527 - val_loss: 0.0091 - val_mae: 0.0431\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0090 - mae: 0.0443 - val_loss: 0.0109 - val_mae: 0.0472\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0105 - mae: 0.0488 - val_loss: 0.0104 - val_mae: 0.0436\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0088 - mae: 0.0438 - val_loss: 0.0091 - val_mae: 0.0451\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0072 - mae: 0.0406 - val_loss: 0.0100 - val_mae: 0.0402\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0090 - mae: 0.0436 - val_loss: 0.0097 - val_mae: 0.0437\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0079 - mae: 0.0411 - val_loss: 0.0086 - val_mae: 0.0460\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0056 - mae: 0.0375 - val_loss: 0.0086 - val_mae: 0.0380\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0051 - mae: 0.0342 - val_loss: 0.0084 - val_mae: 0.0441\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0058 - mae: 0.0366 - val_loss: 0.0068 - val_mae: 0.0318\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0063 - mae: 0.0367 - val_loss: 0.0084 - val_mae: 0.0383\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0054 - mae: 0.0350 - val_loss: 0.0074 - val_mae: 0.0326\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0055 - mae: 0.0333 - val_loss: 0.0113 - val_mae: 0.0536\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0061 - mae: 0.0382 - val_loss: 0.0081 - val_mae: 0.0359\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0055 - mae: 0.0355 - val_loss: 0.0097 - val_mae: 0.0413\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0044 - mae: 0.0310 - val_loss: 0.0087 - val_mae: 0.0341\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0084 - mae: 0.0395 - val_loss: 0.0075 - val_mae: 0.0327\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0043 - mae: 0.0313 - val_loss: 0.0079 - val_mae: 0.0307\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0036 - mae: 0.0270 - val_loss: 0.0103 - val_mae: 0.0460\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0046 - mae: 0.0301 - val_loss: 0.0079 - val_mae: 0.0331\n",
      "Epoch 23: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 128ms/step - loss: 0.0314 - mae: 0.1031 - val_loss: 0.0219 - val_mae: 0.0879\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0302 - mae: 0.0910 - val_loss: 0.0164 - val_mae: 0.0710\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0201 - mae: 0.0692 - val_loss: 0.0164 - val_mae: 0.0614\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0151 - mae: 0.0630 - val_loss: 0.0185 - val_mae: 0.0689\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0142 - mae: 0.0581 - val_loss: 0.0110 - val_mae: 0.0627\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0090 - mae: 0.0521 - val_loss: 0.0138 - val_mae: 0.0593\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0096 - mae: 0.0518 - val_loss: 0.0099 - val_mae: 0.0418\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0067 - mae: 0.0386 - val_loss: 0.0097 - val_mae: 0.0426\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0093 - mae: 0.0454 - val_loss: 0.0111 - val_mae: 0.0513\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0085 - mae: 0.0457 - val_loss: 0.0093 - val_mae: 0.0388\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0074 - mae: 0.0414 - val_loss: 0.0084 - val_mae: 0.0393\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0059 - mae: 0.0387 - val_loss: 0.0078 - val_mae: 0.0331\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0065 - mae: 0.0341 - val_loss: 0.0082 - val_mae: 0.0341\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0059 - mae: 0.0345 - val_loss: 0.0104 - val_mae: 0.0526\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0080 - mae: 0.0437 - val_loss: 0.0095 - val_mae: 0.0389\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0047 - mae: 0.0330 - val_loss: 0.0079 - val_mae: 0.0341\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0065 - mae: 0.0367 - val_loss: 0.0092 - val_mae: 0.0426\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0082 - mae: 0.0402 - val_loss: 0.0077 - val_mae: 0.0364\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0055 - mae: 0.0363 - val_loss: 0.0076 - val_mae: 0.0387\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0046 - mae: 0.0333 - val_loss: 0.0074 - val_mae: 0.0337\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0047 - mae: 0.0318 - val_loss: 0.0078 - val_mae: 0.0325\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0039 - mae: 0.0305 - val_loss: 0.0072 - val_mae: 0.0302\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0043 - mae: 0.0307 - val_loss: 0.0082 - val_mae: 0.0335\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0034 - mae: 0.0265 - val_loss: 0.0095 - val_mae: 0.0417\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0063 - mae: 0.0373 - val_loss: 0.0077 - val_mae: 0.0345\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0042 - mae: 0.0311 - val_loss: 0.0077 - val_mae: 0.0408\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0044 - mae: 0.0347 - val_loss: 0.0079 - val_mae: 0.0385\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0039 - mae: 0.0301 - val_loss: 0.0088 - val_mae: 0.0361\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0031 - mae: 0.0260 - val_loss: 0.0099 - val_mae: 0.0396\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0059 - mae: 0.0371 - val_loss: 0.0095 - val_mae: 0.0397\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0038 - mae: 0.0279 - val_loss: 0.0077 - val_mae: 0.0322\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0026 - mae: 0.0242 - val_loss: 0.0085 - val_mae: 0.0367\n",
      "Epoch 32: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_46 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_47 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - loss: 0.0279 - mae: 0.0933 - val_loss: 0.0230 - val_mae: 0.0912\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0217 - mae: 0.0801 - val_loss: 0.0154 - val_mae: 0.0592\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0138 - mae: 0.0591 - val_loss: 0.0120 - val_mae: 0.0573\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0130 - mae: 0.0550 - val_loss: 0.0136 - val_mae: 0.0566\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0121 - mae: 0.0540 - val_loss: 0.0098 - val_mae: 0.0454\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0101 - mae: 0.0488 - val_loss: 0.0144 - val_mae: 0.0610\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0092 - mae: 0.0483 - val_loss: 0.0095 - val_mae: 0.0427\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0085 - mae: 0.0444 - val_loss: 0.0100 - val_mae: 0.0387\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0062 - mae: 0.0373 - val_loss: 0.0097 - val_mae: 0.0454\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0103 - mae: 0.0492 - val_loss: 0.0093 - val_mae: 0.0477\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0077 - mae: 0.0424 - val_loss: 0.0122 - val_mae: 0.0520\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0068 - mae: 0.0405 - val_loss: 0.0093 - val_mae: 0.0393\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0072 - mae: 0.0394 - val_loss: 0.0097 - val_mae: 0.0384\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0061 - mae: 0.0343 - val_loss: 0.0085 - val_mae: 0.0408\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0059 - mae: 0.0383 - val_loss: 0.0089 - val_mae: 0.0371\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0070 - mae: 0.0389 - val_loss: 0.0117 - val_mae: 0.0435\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0060 - mae: 0.0347 - val_loss: 0.0080 - val_mae: 0.0347\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0053 - mae: 0.0340 - val_loss: 0.0075 - val_mae: 0.0312\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0049 - mae: 0.0291 - val_loss: 0.0075 - val_mae: 0.0304\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0065 - mae: 0.0347 - val_loss: 0.0077 - val_mae: 0.0333\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0043 - mae: 0.0316 - val_loss: 0.0088 - val_mae: 0.0413\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0068 - mae: 0.0398 - val_loss: 0.0107 - val_mae: 0.0498\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0067 - mae: 0.0396 - val_loss: 0.0074 - val_mae: 0.0335\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0044 - mae: 0.0308 - val_loss: 0.0085 - val_mae: 0.0346\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0043 - mae: 0.0278 - val_loss: 0.0071 - val_mae: 0.0314\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0036 - mae: 0.0300 - val_loss: 0.0072 - val_mae: 0.0328\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0044 - mae: 0.0301 - val_loss: 0.0094 - val_mae: 0.0374\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0041 - mae: 0.0291 - val_loss: 0.0073 - val_mae: 0.0311\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0051 - mae: 0.0321 - val_loss: 0.0084 - val_mae: 0.0335\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0051 - mae: 0.0322 - val_loss: 0.0072 - val_mae: 0.0317\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0034 - mae: 0.0286 - val_loss: 0.0079 - val_mae: 0.0343\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0035 - mae: 0.0261 - val_loss: 0.0081 - val_mae: 0.0344\n",
      "Epoch 33/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0033 - mae: 0.0265 - val_loss: 0.0078 - val_mae: 0.0329\n",
      "Epoch 34/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0043 - mae: 0.0294 - val_loss: 0.0079 - val_mae: 0.0301\n",
      "Epoch 35/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0031 - mae: 0.0244 - val_loss: 0.0094 - val_mae: 0.0352\n",
      "Epoch 35: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_34\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_34\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_48 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_49 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 122ms/step - loss: 0.0351 - mae: 0.1062 - val_loss: 0.0208 - val_mae: 0.0740\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0203 - mae: 0.0784 - val_loss: 0.0169 - val_mae: 0.0620\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0193 - mae: 0.0668 - val_loss: 0.0134 - val_mae: 0.0548\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0126 - mae: 0.0548 - val_loss: 0.0112 - val_mae: 0.0478\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0116 - mae: 0.0505 - val_loss: 0.0095 - val_mae: 0.0398\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0083 - mae: 0.0444 - val_loss: 0.0084 - val_mae: 0.0410\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0091 - mae: 0.0457 - val_loss: 0.0100 - val_mae: 0.0455\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0129 - mae: 0.0525 - val_loss: 0.0102 - val_mae: 0.0492\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0130 - mae: 0.0590 - val_loss: 0.0108 - val_mae: 0.0546\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0063 - mae: 0.0453 - val_loss: 0.0086 - val_mae: 0.0437\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0077 - mae: 0.0451 - val_loss: 0.0092 - val_mae: 0.0420\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0091 - mae: 0.0425 - val_loss: 0.0092 - val_mae: 0.0393\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0058 - mae: 0.0346 - val_loss: 0.0078 - val_mae: 0.0334\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0067 - mae: 0.0374 - val_loss: 0.0080 - val_mae: 0.0346\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0068 - mae: 0.0421 - val_loss: 0.0088 - val_mae: 0.0403\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0059 - mae: 0.0388 - val_loss: 0.0080 - val_mae: 0.0329\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0061 - mae: 0.0361 - val_loss: 0.0085 - val_mae: 0.0405\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0044 - mae: 0.0346 - val_loss: 0.0106 - val_mae: 0.0447\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0053 - mae: 0.0338 - val_loss: 0.0072 - val_mae: 0.0343\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0055 - mae: 0.0332 - val_loss: 0.0078 - val_mae: 0.0349\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0047 - mae: 0.0335 - val_loss: 0.0083 - val_mae: 0.0398\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0054 - mae: 0.0354 - val_loss: 0.0067 - val_mae: 0.0327\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0045 - mae: 0.0302 - val_loss: 0.0102 - val_mae: 0.0398\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0051 - mae: 0.0299 - val_loss: 0.0089 - val_mae: 0.0335\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0064 - mae: 0.0360 - val_loss: 0.0086 - val_mae: 0.0420\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0049 - mae: 0.0342 - val_loss: 0.0078 - val_mae: 0.0385\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0044 - mae: 0.0303 - val_loss: 0.0095 - val_mae: 0.0344\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0042 - mae: 0.0286 - val_loss: 0.0073 - val_mae: 0.0336\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0042 - mae: 0.0305 - val_loss: 0.0076 - val_mae: 0.0318\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0032 - mae: 0.0267 - val_loss: 0.0072 - val_mae: 0.0335\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0046 - mae: 0.0292 - val_loss: 0.0082 - val_mae: 0.0350\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0036 - mae: 0.0291 - val_loss: 0.0081 - val_mae: 0.0381\n",
      "Epoch 32: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_35\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_35\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 111ms/step - loss: 0.0292 - mae: 0.1009 - val_loss: 0.0220 - val_mae: 0.0744\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0221 - mae: 0.0772 - val_loss: 0.0215 - val_mae: 0.0834\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0209 - mae: 0.0711 - val_loss: 0.0154 - val_mae: 0.0621\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0113 - mae: 0.0529 - val_loss: 0.0109 - val_mae: 0.0480\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0111 - mae: 0.0531 - val_loss: 0.0141 - val_mae: 0.0489\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0095 - mae: 0.0434 - val_loss: 0.0094 - val_mae: 0.0395\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0068 - mae: 0.0399 - val_loss: 0.0100 - val_mae: 0.0466\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0093 - mae: 0.0456 - val_loss: 0.0099 - val_mae: 0.0412\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0083 - mae: 0.0423 - val_loss: 0.0087 - val_mae: 0.0403\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0091 - mae: 0.0443 - val_loss: 0.0102 - val_mae: 0.0435\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0067 - mae: 0.0413 - val_loss: 0.0099 - val_mae: 0.0421\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0079 - mae: 0.0437 - val_loss: 0.0082 - val_mae: 0.0367\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0054 - mae: 0.0332 - val_loss: 0.0075 - val_mae: 0.0368\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0064 - mae: 0.0383 - val_loss: 0.0070 - val_mae: 0.0315\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0048 - mae: 0.0302 - val_loss: 0.0084 - val_mae: 0.0357\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0055 - mae: 0.0365 - val_loss: 0.0077 - val_mae: 0.0343\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0051 - mae: 0.0308 - val_loss: 0.0068 - val_mae: 0.0333\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0047 - mae: 0.0307 - val_loss: 0.0102 - val_mae: 0.0455\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0053 - mae: 0.0344 - val_loss: 0.0070 - val_mae: 0.0325\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0049 - mae: 0.0325 - val_loss: 0.0077 - val_mae: 0.0343\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0051 - mae: 0.0283 - val_loss: 0.0097 - val_mae: 0.0405\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0053 - mae: 0.0348 - val_loss: 0.0079 - val_mae: 0.0356\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0034 - mae: 0.0275 - val_loss: 0.0079 - val_mae: 0.0337\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0043 - mae: 0.0291 - val_loss: 0.0075 - val_mae: 0.0347\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0038 - mae: 0.0293 - val_loss: 0.0080 - val_mae: 0.0329\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0054 - mae: 0.0317 - val_loss: 0.0073 - val_mae: 0.0337\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0048 - mae: 0.0302 - val_loss: 0.0082 - val_mae: 0.0344\n",
      "Epoch 27: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_36\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_36\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_52 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_53 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 120ms/step - loss: 0.0372 - mae: 0.1125 - val_loss: 0.0215 - val_mae: 0.0795\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0240 - mae: 0.0814 - val_loss: 0.0181 - val_mae: 0.0718\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0190 - mae: 0.0710 - val_loss: 0.0150 - val_mae: 0.0652\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0161 - mae: 0.0618 - val_loss: 0.0110 - val_mae: 0.0568\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0138 - mae: 0.0616 - val_loss: 0.0105 - val_mae: 0.0489\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0113 - mae: 0.0517 - val_loss: 0.0096 - val_mae: 0.0425\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0093 - mae: 0.0429 - val_loss: 0.0082 - val_mae: 0.0413\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0071 - mae: 0.0429 - val_loss: 0.0086 - val_mae: 0.0447\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0084 - mae: 0.0465 - val_loss: 0.0078 - val_mae: 0.0371\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0059 - mae: 0.0352 - val_loss: 0.0085 - val_mae: 0.0382\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0077 - mae: 0.0391 - val_loss: 0.0088 - val_mae: 0.0377\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0070 - mae: 0.0393 - val_loss: 0.0073 - val_mae: 0.0361\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0058 - mae: 0.0373 - val_loss: 0.0083 - val_mae: 0.0359\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0064 - mae: 0.0353 - val_loss: 0.0077 - val_mae: 0.0379\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0056 - mae: 0.0376 - val_loss: 0.0132 - val_mae: 0.0468\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0077 - mae: 0.0400 - val_loss: 0.0094 - val_mae: 0.0422\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0083 - mae: 0.0411 - val_loss: 0.0092 - val_mae: 0.0332\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0064 - mae: 0.0369 - val_loss: 0.0085 - val_mae: 0.0398\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0057 - mae: 0.0342 - val_loss: 0.0118 - val_mae: 0.0511\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0054 - mae: 0.0380 - val_loss: 0.0080 - val_mae: 0.0321\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0046 - mae: 0.0303 - val_loss: 0.0077 - val_mae: 0.0333\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0051 - mae: 0.0327 - val_loss: 0.0084 - val_mae: 0.0341\n",
      "Epoch 22: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_37\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_37\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_54 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_55 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 119ms/step - loss: 0.0299 - mae: 0.1033 - val_loss: 0.0186 - val_mae: 0.0707\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0208 - mae: 0.0741 - val_loss: 0.0138 - val_mae: 0.0581\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0147 - mae: 0.0605 - val_loss: 0.0114 - val_mae: 0.0511\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0159 - mae: 0.0641 - val_loss: 0.0130 - val_mae: 0.0584\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0127 - mae: 0.0556 - val_loss: 0.0103 - val_mae: 0.0435\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0094 - mae: 0.0455 - val_loss: 0.0102 - val_mae: 0.0427\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0095 - mae: 0.0457 - val_loss: 0.0112 - val_mae: 0.0482\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0078 - mae: 0.0452 - val_loss: 0.0095 - val_mae: 0.0372\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0072 - mae: 0.0386 - val_loss: 0.0100 - val_mae: 0.0407\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0060 - mae: 0.0390 - val_loss: 0.0080 - val_mae: 0.0414\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0068 - mae: 0.0404 - val_loss: 0.0079 - val_mae: 0.0378\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0067 - mae: 0.0371 - val_loss: 0.0130 - val_mae: 0.0536\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0064 - mae: 0.0393 - val_loss: 0.0084 - val_mae: 0.0399\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0098 - mae: 0.0472 - val_loss: 0.0142 - val_mae: 0.0553\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0063 - mae: 0.0379 - val_loss: 0.0113 - val_mae: 0.0506\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0059 - mae: 0.0382 - val_loss: 0.0080 - val_mae: 0.0355\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0064 - mae: 0.0391 - val_loss: 0.0084 - val_mae: 0.0346\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0047 - mae: 0.0315 - val_loss: 0.0091 - val_mae: 0.0351\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0056 - mae: 0.0349 - val_loss: 0.0076 - val_mae: 0.0338\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0041 - mae: 0.0307 - val_loss: 0.0105 - val_mae: 0.0391\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0042 - mae: 0.0305 - val_loss: 0.0088 - val_mae: 0.0430\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0055 - mae: 0.0350 - val_loss: 0.0077 - val_mae: 0.0305\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0053 - mae: 0.0307 - val_loss: 0.0080 - val_mae: 0.0364\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0033 - mae: 0.0283 - val_loss: 0.0080 - val_mae: 0.0314\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0041 - mae: 0.0286 - val_loss: 0.0076 - val_mae: 0.0298\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0034 - mae: 0.0260 - val_loss: 0.0080 - val_mae: 0.0328\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0043 - mae: 0.0283 - val_loss: 0.0080 - val_mae: 0.0361\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0028 - mae: 0.0267 - val_loss: 0.0090 - val_mae: 0.0381\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0054 - mae: 0.0328 - val_loss: 0.0080 - val_mae: 0.0316\n",
      "Epoch 29: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_38\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_38\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_56 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_57 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 116ms/step - loss: 0.0272 - mae: 0.0976 - val_loss: 0.0218 - val_mae: 0.1067\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0257 - mae: 0.1018 - val_loss: 0.0202 - val_mae: 0.0647\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0202 - mae: 0.0740 - val_loss: 0.0130 - val_mae: 0.0505\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0106 - mae: 0.0483 - val_loss: 0.0140 - val_mae: 0.0554\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0147 - mae: 0.0559 - val_loss: 0.0091 - val_mae: 0.0464\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0093 - mae: 0.0462 - val_loss: 0.0077 - val_mae: 0.0342\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0086 - mae: 0.0402 - val_loss: 0.0161 - val_mae: 0.0579\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0113 - mae: 0.0492 - val_loss: 0.0083 - val_mae: 0.0398\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0085 - mae: 0.0448 - val_loss: 0.0082 - val_mae: 0.0464\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0075 - mae: 0.0483 - val_loss: 0.0075 - val_mae: 0.0397\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0067 - mae: 0.0409 - val_loss: 0.0092 - val_mae: 0.0434\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0068 - mae: 0.0405 - val_loss: 0.0081 - val_mae: 0.0416\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0095 - mae: 0.0466 - val_loss: 0.0077 - val_mae: 0.0341\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0065 - mae: 0.0376 - val_loss: 0.0098 - val_mae: 0.0393\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0076 - mae: 0.0398 - val_loss: 0.0079 - val_mae: 0.0370\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0073 - mae: 0.0409 - val_loss: 0.0076 - val_mae: 0.0357\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0057 - mae: 0.0345 - val_loss: 0.0084 - val_mae: 0.0363\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0053 - mae: 0.0356 - val_loss: 0.0076 - val_mae: 0.0332\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0051 - mae: 0.0328 - val_loss: 0.0073 - val_mae: 0.0322\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0053 - mae: 0.0330 - val_loss: 0.0075 - val_mae: 0.0356\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0047 - mae: 0.0340 - val_loss: 0.0093 - val_mae: 0.0410\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0061 - mae: 0.0358 - val_loss: 0.0115 - val_mae: 0.0445\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0071 - mae: 0.0368 - val_loss: 0.0078 - val_mae: 0.0329\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0054 - mae: 0.0313 - val_loss: 0.0080 - val_mae: 0.0379\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0052 - mae: 0.0356 - val_loss: 0.0095 - val_mae: 0.0376\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0036 - mae: 0.0298 - val_loss: 0.0085 - val_mae: 0.0348\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0044 - mae: 0.0285 - val_loss: 0.0085 - val_mae: 0.0342\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0045 - mae: 0.0303 - val_loss: 0.0087 - val_mae: 0.0412\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0042 - mae: 0.0348 - val_loss: 0.0081 - val_mae: 0.0344\n",
      "Epoch 29: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_39\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_39\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m11,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_58 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,259,777</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,259,777\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 126ms/step - loss: 0.0280 - mae: 0.0973 - val_loss: 0.0199 - val_mae: 0.0672\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0202 - mae: 0.0688 - val_loss: 0.0154 - val_mae: 0.0551\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0138 - mae: 0.0569 - val_loss: 0.0128 - val_mae: 0.0606\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0130 - mae: 0.0540 - val_loss: 0.0126 - val_mae: 0.0463\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0110 - mae: 0.0497 - val_loss: 0.0092 - val_mae: 0.0401\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0079 - mae: 0.0425 - val_loss: 0.0080 - val_mae: 0.0387\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0069 - mae: 0.0378 - val_loss: 0.0088 - val_mae: 0.0402\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0100 - mae: 0.0446 - val_loss: 0.0079 - val_mae: 0.0359\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0101 - mae: 0.0455 - val_loss: 0.0088 - val_mae: 0.0432\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0071 - mae: 0.0399 - val_loss: 0.0090 - val_mae: 0.0446\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0074 - mae: 0.0462 - val_loss: 0.0073 - val_mae: 0.0413\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0075 - mae: 0.0419 - val_loss: 0.0076 - val_mae: 0.0393\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0054 - mae: 0.0370 - val_loss: 0.0077 - val_mae: 0.0322\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0051 - mae: 0.0329 - val_loss: 0.0073 - val_mae: 0.0389\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0066 - mae: 0.0384 - val_loss: 0.0097 - val_mae: 0.0409\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0055 - mae: 0.0373 - val_loss: 0.0079 - val_mae: 0.0346\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0052 - mae: 0.0372 - val_loss: 0.0085 - val_mae: 0.0357\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0044 - mae: 0.0293 - val_loss: 0.0076 - val_mae: 0.0320\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0052 - mae: 0.0313 - val_loss: 0.0105 - val_mae: 0.0416\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0059 - mae: 0.0349 - val_loss: 0.0083 - val_mae: 0.0425\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0040 - mae: 0.0298 - val_loss: 0.0088 - val_mae: 0.0338\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0050 - mae: 0.0290 - val_loss: 0.0082 - val_mae: 0.0317\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0062 - mae: 0.0335 - val_loss: 0.0083 - val_mae: 0.0331\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0044 - mae: 0.0290 - val_loss: 0.0078 - val_mae: 0.0306\n",
      "Epoch 24: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1259, 1)\n",
      "Test RMSE: 550.024\n",
      "Test MAE: 234.585\n",
      "Test R2 Score:  0.8538045230151938\n",
      "MAPE 0.6562217414765625\n",
      "Test MBE 21.47796156200784\n",
      "nRMSE 0.9458405905850958\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "(1890, 1)\n",
      "Test RMSE: 619.953\n",
      "Test MAE: 297.222\n",
      "Test R2 Score:  0.8390889839962017\n",
      "MAPE 0.5332206350431351\n",
      "Test MBE -61.80355965005809\n",
      "nRMSE 0.8017083446187029\n",
      "MAE: [297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355, 297.22228492890355]\n",
      "RMSE: [619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617, 619.9532693911617]\n",
      "R^2: [0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017, 0.8390889839962017]\n",
      "MAPE: [0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351, 0.5332206350431351]\n",
      "MBE: [-61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809, -61.80355965005809]\n",
      "nRMSE: [0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029, 0.8017083446187029]\n",
      "Mean MAE: 297.2222849289036\n",
      "Mean RMSE: 619.9532693911618\n",
      "Mean R^2: 0.8390889839962018\n",
      "Mean MAPE: 0.533220635043135\n",
      "Mean MBE: -61.80355965005809\n",
      "Mean nRMSE: 0.8017083446187028\n"
     ]
    }
   ],
   "source": [
    "mae_list = []\n",
    "rmse_list = []\n",
    "r_square_list = []\n",
    "mape_list = []\n",
    "mbe_list = []\n",
    "nRMSE_list = []\n",
    "num_iterations = 20\n",
    "#num_iterations = 2\n",
    "for i in range(num_iterations):\n",
    "    # print(\"Shape of x_train:\", x_train.shape)\n",
    "    # print(\"Shape of y_train:\", y_train.shape)\n",
    "    # print(\"Shape of x_test:\", x_test.shape)\n",
    "    # print(\"Shape of y_test:\", y_test.shape)\n",
    "    model = createModel()\n",
    "    keras.config.disable_traceback_filtering()\n",
    "    fit_predict_stats(model)\n",
    "\n",
    "# sns.set_style(\"darkgrid\")\n",
    "# for true, hat in zip(true_values, predicted_values):\n",
    "#     plt.figure()\n",
    "#     plt.plot(true[1], color=\"green\")\n",
    "#     plt.plot(hat[1], color=\"red\")\n",
    "#     plt.savefig('plots/lstm_base_plot.png')\n",
    "    #plt.show()\n",
    "\n",
    "print(\"MAE:\", mae_list)\n",
    "print(\"RMSE:\", rmse_list)\n",
    "print(\"R^2:\", r_square_list)\n",
    "print(\"MAPE:\", mape_list)\n",
    "print(\"MBE:\", mbe_list)\n",
    "print(\"nRMSE:\", nRMSE_list)\n",
    "\n",
    "print(\"Mean MAE:\", np.mean(mae_list))\n",
    "print(\"Mean RMSE:\", np.mean(rmse_list))\n",
    "print(\"Mean R^2:\", np.mean(r_square_list))\n",
    "print(\"Mean MAPE:\", np.mean(mape_list))\n",
    "print(\"Mean MBE:\", np.mean(mbe_list))\n",
    "print(\"Mean nRMSE:\", np.mean(nRMSE_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8856), started 3:56:15 ago. (Use '!kill 8856' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-51ada2b6b3361c3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-51ada2b6b3361c3\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!rm -rf \"c:/work/Honours code/Transfer learning/LSTM/logs/\"\n",
    "#!rm -r \"c:/work/Honours code/Transfer learning/LSTM/logs/\"\n",
    "%load_ext tensorboard\n",
    "#%tensorboard --logdir LSTM/logs/\n",
    "%tensorboard --logdir  \"c:/work/Honours code/Transfer learning/LSTM/logs/\"\n",
    "#%tensorboard --logdir  \"./LSTM/logs/\"\n",
    "\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "#!kill 10060"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "Code credits to Xiaomin Chang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_training(params):\n",
    "    learning_rate = params['learning_rate']\n",
    "    lstm_units_1 = params['lstm_units_1']\n",
    "    lstm_units_2 = params['lstm_units_2']\n",
    "    lstm_units_3 = params['lstm_units_3']\n",
    "    batch_size = params['batch_size']\n",
    "    validation_split = params['validation_split']\n",
    "    \n",
    "    # create the model\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(lstm_units_1, activation='relu', return_sequences=True), input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(lstm_units_2, activation='relu', return_sequences=True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(lstm_units_3, activation='relu', return_sequences=False)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate), metrics=['mae'])\n",
    "\n",
    "    try:\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "        \n",
    "        history = model.fit(x_train, y_train, batch_size=batch_size, validation_data=(x_val, y_val))\n",
    "\n",
    "        print(history.history) \n",
    "    \n",
    "        #loss = history.history['val_loss'][-1]\n",
    "        loss = np.min(history.history['val_loss'])\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "    except Exception as e:\n",
    "        print(\"Error: {}\".format(e))\n",
    "        print(\"Params: {}\".format(params))\n",
    "        return {'loss': float('inf'), 'status': STATUS_FAIL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.1)),\n",
    "    #'learning_rate': hp.choice('learning_rate', [0.001, 0.01, 0.1]),\n",
    "    'batch_size': hp.choice('batch_size', [32, 64, 128, 256]), \n",
    "    'lstm_units_1': hp.choice('lstm_units_1', [16, 32, 64]),\n",
    "    'lstm_units_2': hp.choice('lstm_units_2', [32, 64, 128]),\n",
    "    'lstm_units_3': hp.choice('lstm_units_3', [64, 128, 256]), \n",
    "    'validation_split': hp.uniform('validation_split', 0.1, 0.2),\n",
    "    'layer1_dropout': hp.uniform('layer1_dropout', 0.1, 0.5),\n",
    "    'layer2_dropout': hp.uniform('layer2_dropout', 0.1, 0.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 11s/step - loss: 0.0504 - mae: 0.0906\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0472 - mae: 0.0869\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0441 - mae: 0.0833\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0423 - mae: 0.0816\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0415 - mae: 0.0813\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 517ms/step - loss: 0.0410 - mae: 0.0811 - val_loss: 0.0523 - val_mae: 0.1131\n",
      "\n",
      "{'loss': [0.03846614435315132], 'mae': [0.07994460314512253], 'val_loss': [0.052317313849925995], 'val_mae': [0.113103948533535]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 12s/step - loss: 0.0289 - mae: 0.0723\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.0618 - mae: 0.1501\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 0.0665 - mae: 0.1642\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 0.0666 - mae: 0.1639\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 0.0660 - mae: 0.1610\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 636ms/step - loss: 0.0656 - mae: 0.1590 - val_loss: 0.0590 - val_mae: 0.1140\n",
      "\n",
      "{'loss': [0.06358589231967926], 'mae': [0.14911897480487823], 'val_loss': [0.05896063148975372], 'val_mae': [0.11400654911994934]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 16s/step - loss: 0.0397 - mae: 0.0908\n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0416 - mae: 0.0875 \n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0404 - mae: 0.0909\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0389 - mae: 0.0956\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 201ms/step - loss: 0.0383 - mae: 0.0984 - val_loss: 0.0429 - val_mae: 0.1430\n",
      "\n",
      "{'loss': [0.03568073734641075], 'mae': [0.11070618778467178], 'val_loss': [0.04294373467564583], 'val_mae': [0.1429523527622223]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:23\u001b[0m 11s/step - loss: 0.0120 - mae: 0.0401\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0384 - mae: 0.0761 \n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0406 - mae: 0.0821\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0404 - mae: 0.0844\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0395 - mae: 0.0851\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0387 - mae: 0.0858\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0378 - mae: 0.0863\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0372 - mae: 0.0870\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0370 - mae: 0.0879\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0366 - mae: 0.0887\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0364 - mae: 0.0893\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0362 - mae: 0.0901\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0361 - mae: 0.0909\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 68ms/step - loss: 0.0359 - mae: 0.0917 - val_loss: 0.0438 - val_mae: 0.1299\n",
      "\n",
      "{'loss': [0.03437451273202896], 'mae': [0.10023001581430435], 'val_loss': [0.043753933161497116], 'val_mae': [0.1299189031124115]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 12s/step - loss: 0.0381 - mae: 0.0787\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 0.0367 - mae: 0.0791\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.0362 - mae: 0.0806\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.0362 - mae: 0.0825\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.0362 - mae: 0.0842\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 702ms/step - loss: 0.0362 - mae: 0.0853 - val_loss: 0.0458 - val_mae: 0.1280\n",
      "\n",
      "{'loss': [0.03620564565062523], 'mae': [0.09103355556726456], 'val_loss': [0.04581297188997269], 'val_mae': [0.1279517412185669]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 11s/step - loss: 0.0389 - mae: 0.0780\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0381 - mae: 0.0847 \n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0372 - mae: 0.0906\n",
      "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0371 - mae: 0.0961\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0368 - mae: 0.1001\n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0364 - mae: 0.1029\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0361 - mae: 0.1049\n",
      "\u001b[1m 8/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0358 - mae: 0.1062\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0355 - mae: 0.1069\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0351 - mae: 0.1074\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 291ms/step - loss: 0.0349 - mae: 0.1077 - val_loss: 0.0324 - val_mae: 0.1017\n",
      "\n",
      "{'loss': [0.032171331346035004], 'mae': [0.11107416450977325], 'val_loss': [0.0324091799557209], 'val_mae': [0.10165635496377945]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 17s/step - loss: 0.0330 - mae: 0.0791\n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0368 - mae: 0.0917 \n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0374 - mae: 0.1004\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0365 - mae: 0.1052\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0362 - mae: 0.1082\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 210ms/step - loss: 0.0357 - mae: 0.1096 - val_loss: 0.0365 - val_mae: 0.1072\n",
      "\n",
      "{'loss': [0.033817000687122345], 'mae': [0.1161179170012474], 'val_loss': [0.03649274632334709], 'val_mae': [0.10716162621974945]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 11s/step - loss: 0.0355 - mae: 0.0789\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0387 - mae: 0.0818\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0397 - mae: 0.0821\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0399 - mae: 0.0818\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0400 - mae: 0.0815\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 466ms/step - loss: 0.0401 - mae: 0.0813 - val_loss: 0.0550 - val_mae: 0.1128\n",
      "\n",
      "{'loss': [0.04040687903761864], 'mae': [0.08051960170269012], 'val_loss': [0.05500293895602226], 'val_mae': [0.11282217502593994]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 11s/step - loss: 0.0421 - mae: 0.1033\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2815 - mae: 0.3347\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2623 - mae: 0.3164\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 462ms/step - loss: 0.2542 - mae: 0.3084 - val_loss: 0.0644 - val_mae: 0.1353\n",
      "\n",
      "{'loss': [0.21341700851917267], 'mae': [0.2686101198196411], 'val_loss': [0.06439018994569778], 'val_mae': [0.1353369504213333]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 11s/step - loss: 0.0474 - mae: 0.0869\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 6600083.0000 - mae: 981.9048\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 7333429.5000 - mae: 1091.5936\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 7150095.5000 - mae: 1064.5596\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 6793705.5000 - mae: 1011.6298\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 486ms/step - loss: 6556112.0000 - mae: 976.3433 - val_loss: 1.5717 - val_mae: 1.1021\n",
      "\n",
      "{'loss': [5368145.0], 'mae': [799.9105834960938], 'val_loss': [1.5717369318008423], 'val_mae': [1.1020593643188477]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:12\u001b[0m 17s/step - loss: 0.0460 - mae: 0.0825\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0359 - mae: 0.0826  \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0340 - mae: 0.0883\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0337 - mae: 0.0904\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0329 - mae: 0.0924\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0327 - mae: 0.0939\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0328 - mae: 0.0949\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0328 - mae: 0.0958\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0328 - mae: 0.0966\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0327 - mae: 0.0973\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0327 - mae: 0.0981\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0326 - mae: 0.0986\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0326 - mae: 0.0991\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0324 - mae: 0.0999\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0323 - mae: 0.1003\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0321 - mae: 0.1009\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0320 - mae: 0.1013\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0320 - mae: 0.1017\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0320 - mae: 0.1020\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0320 - mae: 0.1022\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0319 - mae: 0.1025\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0318 - mae: 0.1027\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0318 - mae: 0.1029\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0317 - mae: 0.1031\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0316 - mae: 0.1032\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0315 - mae: 0.1033\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0315 - mae: 0.1033\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0314 - mae: 0.1033\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0313 - mae: 0.1033\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0312 - mae: 0.1032\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0311 - mae: 0.1031\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 113ms/step - loss: 0.0310 - mae: 0.1030 - val_loss: 0.0342 - val_mae: 0.0937\n",
      "\n",
      "{'loss': [0.029415873810648918], 'mae': [0.10041427612304688], 'val_loss': [0.03415224328637123], 'val_mae': [0.09369948506355286]}\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:35\u001b[0m 11s/step - loss: 0.0231 - mae: 0.0577\n",
      "\u001b[1m 2/20\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1513 - mae: 0.2227 \n",
      "\u001b[1m 4/20\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1622 - mae: 0.2410\n",
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1573 - mae: 0.2354\n",
      "\u001b[1m 6/20\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1511 - mae: 0.2278\n",
      "\u001b[1m 8/20\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1395 - mae: 0.2140\n",
      "\u001b[1m 9/20\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1344 - mae: 0.2080\n",
      "\u001b[1m10/20\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1297 - mae: 0.2023\n",
      "\u001b[1m11/20\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1253 - mae: 0.1969\n",
      "\u001b[1m12/20\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1213 - mae: 0.1918\n",
      "\u001b[1m13/20\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1176 - mae: 0.1871\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1117 - mae: 0.1794\n",
      "\u001b[1m16/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1092 - mae: 0.1761\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1068 - mae: 0.1731\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1046 - mae: 0.1704\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1025 - mae: 0.1681\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 147ms/step - loss: 0.0989 - mae: 0.1642 - val_loss: 0.0359 - val_mae: 0.1379\n",
      "\n",
      "{'loss': [0.06448718160390854], 'mae': [0.12712061405181885], 'val_loss': [0.03592415899038315], 'val_mae': [0.13793720304965973]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 12s/step - loss: 0.0443 - mae: 0.0836\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0434 - mae: 0.0893\n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0416 - mae: 0.0947\n",
      "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0409 - mae: 0.0999\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0400 - mae: 0.1031\n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0391 - mae: 0.1051\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0384 - mae: 0.1066\n",
      "\u001b[1m 8/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0377 - mae: 0.1074\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0371 - mae: 0.1076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0365 - mae: 0.1077\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 321ms/step - loss: 0.0360 - mae: 0.1077 - val_loss: 0.0287 - val_mae: 0.0953\n",
      "\n",
      "{'loss': [0.031036168336868286], 'mae': [0.10847925394773483], 'val_loss': [0.028686271980404854], 'val_mae': [0.09528528153896332]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:17\u001b[0m 11s/step - loss: 0.0212 - mae: 0.0506\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0316 - mae: 0.0930 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0337 - mae: 0.1012\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0336 - mae: 0.1037\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0332 - mae: 0.1049\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0329 - mae: 0.1053\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0325 - mae: 0.1052\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0318 - mae: 0.1041\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0311 - mae: 0.1025\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0303 - mae: 0.1011\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0297 - mae: 0.0999\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0292 - mae: 0.0989\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0285 - mae: 0.0976\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0281 - mae: 0.0969\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0278 - mae: 0.0963\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0275 - mae: 0.0959\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0272 - mae: 0.0952\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0270 - mae: 0.0947\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0268 - mae: 0.0943\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.0266 - mae: 0.0939 - val_loss: 0.0146 - val_mae: 0.0810\n",
      "\n",
      "{'loss': [0.022915516048669815], 'mae': [0.08615987002849579], 'val_loss': [0.014616209082305431], 'val_mae': [0.08104945719242096]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:22\u001b[0m 11s/step - loss: 0.0462 - mae: 0.0865\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0356 - mae: 0.0834 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0333 - mae: 0.0907\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0324 - mae: 0.0935\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0319 - mae: 0.0983\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0318 - mae: 0.1001\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0317 - mae: 0.1029\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0317 - mae: 0.1047\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0319 - mae: 0.1062\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0320 - mae: 0.1073\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0320 - mae: 0.1080\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0320 - mae: 0.1082\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0318 - mae: 0.1081\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0317 - mae: 0.1080\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0316 - mae: 0.1079\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0315 - mae: 0.1077\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0314 - mae: 0.1076\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0313 - mae: 0.1073\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0311 - mae: 0.1068\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0309 - mae: 0.1063\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0308 - mae: 0.1059\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0305 - mae: 0.1053\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0303 - mae: 0.1048\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0302 - mae: 0.1046\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0300 - mae: 0.1042\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 270ms/step - loss: 0.0300 - mae: 0.1040 - val_loss: 0.0202 - val_mae: 0.0753\n",
      "\n",
      "{'loss': [0.0269660372287035], 'mae': [0.09680598974227905], 'val_loss': [0.020244501531124115], 'val_mae': [0.07534243911504745]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 11s/step - loss: 0.0181 - mae: 0.0579\n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0202 - mae: 0.0679 \n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0237 - mae: 0.0792\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0251 - mae: 0.0863\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0260 - mae: 0.0909\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 219ms/step - loss: 0.0268 - mae: 0.0940 - val_loss: 0.0317 - val_mae: 0.1002\n",
      "\n",
      "{'loss': [0.03003033995628357], 'mae': [0.10794896632432938], 'val_loss': [0.03173540160059929], 'val_mae': [0.10024850070476532]}\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:34\u001b[0m 11s/step - loss: 0.0310 - mae: 0.0755\n",
      "\u001b[1m 4/20\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0331 - mae: 0.0786 \n",
      "\u001b[1m 6/20\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0354 - mae: 0.0862\n",
      "\u001b[1m 9/20\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0366 - mae: 0.0952\n",
      "\u001b[1m12/20\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0361 - mae: 0.1003\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0357 - mae: 0.1033\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0354 - mae: 0.1049\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0351 - mae: 0.1054\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 122ms/step - loss: 0.0350 - mae: 0.1057 - val_loss: 0.0343 - val_mae: 0.1057\n",
      "\n",
      "{'loss': [0.03266201913356781], 'mae': [0.10988032072782516], 'val_loss': [0.03434675186872482], 'val_mae': [0.10570729523897171]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 12s/step - loss: 0.0428 - mae: 0.0765\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0410 - mae: 0.0861\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0399 - mae: 0.0942\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0389 - mae: 0.0996\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0382 - mae: 0.1031\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 599ms/step - loss: 0.0376 - mae: 0.1053 - val_loss: 0.0405 - val_mae: 0.1201\n",
      "\n",
      "{'loss': [0.03502155840396881], 'mae': [0.11667034775018692], 'val_loss': [0.040462322533130646], 'val_mae': [0.12011213600635529]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:38\u001b[0m 12s/step - loss: 0.0259 - mae: 0.0661\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.0293 - mae: 0.0765 \n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0338 - mae: 0.0852\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0341 - mae: 0.0886\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0339 - mae: 0.0910\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0334 - mae: 0.0929\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0328 - mae: 0.0942\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0329 - mae: 0.0961\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0326 - mae: 0.0972\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0325 - mae: 0.0983\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0327 - mae: 0.0996\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0330 - mae: 0.1011\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0331 - mae: 0.1022\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0331 - mae: 0.1032\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0331 - mae: 0.1042\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0330 - mae: 0.1049\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0329 - mae: 0.1055\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0328 - mae: 0.1061\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0329 - mae: 0.1067\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0328 - mae: 0.1071\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0328 - mae: 0.1074\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0328 - mae: 0.1076\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0327 - mae: 0.1078\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0327 - mae: 0.1078\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0326 - mae: 0.1078\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0325 - mae: 0.1078\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0325 - mae: 0.1079\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0324 - mae: 0.1079\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0324 - mae: 0.1079\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0323 - mae: 0.1079\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0323 - mae: 0.1079\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0322 - mae: 0.1078\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0322 - mae: 0.1077\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0321 - mae: 0.1075\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0320 - mae: 0.1074\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0319 - mae: 0.1072\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0318 - mae: 0.1071\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0317 - mae: 0.1069\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0316 - mae: 0.1067\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0315 - mae: 0.1065\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 127ms/step - loss: 0.0315 - mae: 0.1063 - val_loss: 0.0292 - val_mae: 0.0852\n",
      "\n",
      "{'loss': [0.027896706014871597], 'mae': [0.0987386628985405], 'val_loss': [0.029161861166357994], 'val_mae': [0.0852377712726593]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 12s/step - loss: 0.0480 - mae: 0.0863\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3698 - mae: 0.3498 \n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.4027 - mae: 0.3813\n",
      "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3919 - mae: 0.3740\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3728 - mae: 0.3591\n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3531 - mae: 0.3438\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3351 - mae: 0.3297\n",
      "\u001b[1m 8/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3187 - mae: 0.3168\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3039 - mae: 0.3049\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.2909 - mae: 0.2945\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - loss: 0.2803 - mae: 0.2860 - val_loss: 0.0582 - val_mae: 0.1100\n",
      "\n",
      "{'loss': [0.17388035356998444], 'mae': [0.20081225037574768], 'val_loss': [0.05820536985993385], 'val_mae': [0.10998440533876419]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:20\u001b[0m 11s/step - loss: 0.0661 - mae: 0.1001\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0928 - mae: 0.1862 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0849 - mae: 0.1759\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0768 - mae: 0.1616\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0710 - mae: 0.1512\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0672 - mae: 0.1448\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0639 - mae: 0.1406\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0612 - mae: 0.1377\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0591 - mae: 0.1354\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0581 - mae: 0.1345\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0563 - mae: 0.1327\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0548 - mae: 0.1310\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0533 - mae: 0.1292\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0519 - mae: 0.1276\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0507 - mae: 0.1258\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0494 - mae: 0.1240\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0484 - mae: 0.1224\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0474 - mae: 0.1209\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0466 - mae: 0.1196\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0458 - mae: 0.1185\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - loss: 0.0447 - mae: 0.1169 - val_loss: 0.0243 - val_mae: 0.0953\n",
      "\n",
      "{'loss': [0.03151008486747742], 'mae': [0.09726196527481079], 'val_loss': [0.024290092289447784], 'val_mae': [0.09529449045658112]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:18\u001b[0m 11s/step - loss: 0.0198 - mae: 0.0620\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0199 - mae: 0.0833 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0205 - mae: 0.0855\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0212 - mae: 0.0861\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0220 - mae: 0.0879\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0230 - mae: 0.0917\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0231 - mae: 0.0922\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0232 - mae: 0.0921\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0234 - mae: 0.0920\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0235 - mae: 0.0918\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0235 - mae: 0.0915\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0238 - mae: 0.0909\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0241 - mae: 0.0906\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0244 - mae: 0.0902\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0245 - mae: 0.0898\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0246 - mae: 0.0896\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0247 - mae: 0.0893\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0247 - mae: 0.0891\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0247 - mae: 0.0889\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0247 - mae: 0.0887\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0247 - mae: 0.0885\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0247 - mae: 0.0884\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0247 - mae: 0.0883\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 86ms/step - loss: 0.0247 - mae: 0.0882 - val_loss: 0.0131 - val_mae: 0.0715\n",
      "\n",
      "{'loss': [0.024083280935883522], 'mae': [0.08435755223035812], 'val_loss': [0.013066052459180355], 'val_mae': [0.0715155377984047]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:30\u001b[0m 12s/step - loss: 0.0652 - mae: 0.1120\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0598 - mae: 0.1425 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0533 - mae: 0.1375\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0489 - mae: 0.1304\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0461 - mae: 0.1254\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0440 - mae: 0.1225\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0425 - mae: 0.1203\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0410 - mae: 0.1180\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0398 - mae: 0.1156\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0383 - mae: 0.1123\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0371 - mae: 0.1095\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0368 - mae: 0.1087\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0361 - mae: 0.1072\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0354 - mae: 0.1058\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0349 - mae: 0.1046\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0345 - mae: 0.1036\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0341 - mae: 0.1026\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0337 - mae: 0.1018\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0333 - mae: 0.1011\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0330 - mae: 0.1004\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - loss: 0.0328 - mae: 0.1001 - val_loss: 0.0182 - val_mae: 0.0666\n",
      "\n",
      "{'loss': [0.026462364941835403], 'mae': [0.08776479959487915], 'val_loss': [0.018248144537210464], 'val_mae': [0.06656516343355179]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:22\u001b[0m 11s/step - loss: 0.0362 - mae: 0.0744\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 3225279.2500 - mae: 849.6670\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2980168.5000 - mae: 785.8202\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2642115.0000 - mae: 697.2955\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2359595.0000 - mae: 623.1428\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2132096.0000 - mae: 563.3611\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1867373.1250 - mae: 493.7499\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1794487.6250 - mae: 474.5787\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1666238.1250 - mae: 440.8430\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1609507.1250 - mae: 425.9192\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1508141.3750 - mae: 399.2474\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1420161.1250 - mae: 376.0912\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1343008.3750 - mae: 355.7754\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1274740.5000 - mae: 337.7927\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1213857.2500 - mae: 321.7486\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1159181.5000 - mae: 307.3351\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1109777.1250 - mae: 294.3065\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1086810.0000 - mae: 288.2483\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1043942.8125 - mae: 276.9381\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1023903.8750 - mae: 271.6499\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 986313.8750 - mae: 261.7278 \n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - loss: 935802.7500 - mae: 248.3921 - val_loss: 0.0694 - val_mae: 0.1757\n",
      "\n",
      "{'loss': [295128.46875], 'mae': [79.24187469482422], 'val_loss': [0.06944244354963303], 'val_mae': [0.1756574511528015]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:59\u001b[0m 12s/step - loss: 0.0421 - mae: 0.0965\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0375 - mae: 0.1060 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0364 - mae: 0.1086\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0345 - mae: 0.1071\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0331 - mae: 0.1058\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0325 - mae: 0.1054\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0322 - mae: 0.1052\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0317 - mae: 0.1047\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0315 - mae: 0.1045\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0313 - mae: 0.1043\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0312 - mae: 0.1040\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0311 - mae: 0.1038\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0309 - mae: 0.1033\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0308 - mae: 0.1027\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0305 - mae: 0.1021\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0303 - mae: 0.1014\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0300 - mae: 0.1004\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0296 - mae: 0.0995\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0295 - mae: 0.0992\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0294 - mae: 0.0989\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0293 - mae: 0.0986\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 86ms/step - loss: 0.0289 - mae: 0.0977 - val_loss: 0.0347 - val_mae: 0.0864\n",
      "\n",
      "{'loss': [0.024613747373223305], 'mae': [0.08670592308044434], 'val_loss': [0.03474455699324608], 'val_mae': [0.0864499881863594]}\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:10\u001b[0m 19s/step - loss: 0.0857 - mae: 0.1403\n",
      "\u001b[1m 3/20\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0792 - mae: 0.1763 \n",
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0693 - mae: 0.1649\n",
      "\u001b[1m 7/20\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0626 - mae: 0.1536\n",
      "\u001b[1m 9/20\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0575 - mae: 0.1453\n",
      "\u001b[1m11/20\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0537 - mae: 0.1397\n",
      "\u001b[1m13/20\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0508 - mae: 0.1351\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0485 - mae: 0.1312\n",
      "\u001b[1m16/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0475 - mae: 0.1294\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0466 - mae: 0.1277\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0457 - mae: 0.1260\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0450 - mae: 0.1246\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 142ms/step - loss: 0.0438 - mae: 0.1221 - val_loss: 0.0278 - val_mae: 0.0816\n",
      "\n",
      "{'loss': [0.03169097378849983], 'mae': [0.09791290760040283], 'val_loss': [0.027787938714027405], 'val_mae': [0.08158856630325317]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:26\u001b[0m 11s/step - loss: 0.0480 - mae: 0.0944\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 205.8608 - mae: 7.1024\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 190.2168 - mae: 6.5709\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 168.6416 - mae: 5.8347\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 150.6113 - mae: 5.2202\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 136.0952 - mae: 4.7294\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 124.2991 - mae: 4.3314\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 114.5541 - mae: 4.0023\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 106.3711 - mae: 3.7259\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 102.7513 - mae: 3.6037\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 99.3984 - mae: 3.4904 \n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 96.2833 - mae: 3.3850\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 90.6695 - mae: 3.1950\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 88.1301 - mae: 3.1088\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 83.5038 - mae: 2.9516\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 79.3935 - mae: 2.8119\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 75.7147 - mae: 2.6869\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 72.4005 - mae: 2.5746\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 69.3972 - mae: 2.4728\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 66.6616 - mae: 2.3800\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 65.3828 - mae: 2.3367\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 64.1580 - mae: 2.2950\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 61.8571 - mae: 2.2168\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 83ms/step - loss: 59.7603 - mae: 2.1454 - val_loss: 0.0360 - val_mae: 0.0898\n",
      "\n",
      "{'loss': [18.873138427734375], 'mae': [0.7535099387168884], 'val_loss': [0.035970546305179596], 'val_mae': [0.08981899917125702]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:25\u001b[0m 11s/step - loss: 0.0394 - mae: 0.0648\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0381 - mae: 0.0981 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0365 - mae: 0.0997\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0352 - mae: 0.0979\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0344 - mae: 0.0970\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0336 - mae: 0.0963\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0329 - mae: 0.0959\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0324 - mae: 0.0959\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0318 - mae: 0.0954\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0311 - mae: 0.0944\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0305 - mae: 0.0933\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0300 - mae: 0.0925\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0297 - mae: 0.0921\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0296 - mae: 0.0918\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0294 - mae: 0.0916\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0291 - mae: 0.0914\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0290 - mae: 0.0913\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0289 - mae: 0.0911\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0286 - mae: 0.0908\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0284 - mae: 0.0904\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0281 - mae: 0.0900\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0279 - mae: 0.0895\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0276 - mae: 0.0891\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 94ms/step - loss: 0.0275 - mae: 0.0889 - val_loss: 0.0159 - val_mae: 0.0620\n",
      "\n",
      "{'loss': [0.02303297631442547], 'mae': [0.08049023151397705], 'val_loss': [0.015920497477054596], 'val_mae': [0.06201742962002754]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:26\u001b[0m 11s/step - loss: 0.0176 - mae: 0.0403\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0614 - mae: 0.1456 \n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0596 - mae: 0.1438\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.0581 - mae: 0.1405\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0559 - mae: 0.1342\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0539 - mae: 0.1281\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0525 - mae: 0.1243\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0516 - mae: 0.1233\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0506 - mae: 0.1227\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0498 - mae: 0.1218\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0489 - mae: 0.1208\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0486 - mae: 0.1203\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0477 - mae: 0.1193\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0474 - mae: 0.1189\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0467 - mae: 0.1182\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0461 - mae: 0.1175\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0456 - mae: 0.1169\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0451 - mae: 0.1163\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0447 - mae: 0.1158\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0445 - mae: 0.1156\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0440 - mae: 0.1151\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0438 - mae: 0.1149\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0433 - mae: 0.1145\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 92ms/step - loss: 0.0429 - mae: 0.1141 - val_loss: 0.0227 - val_mae: 0.0808\n",
      "\n",
      "{'loss': [0.03462732955813408], 'mae': [0.1060803234577179], 'val_loss': [0.022723693400621414], 'val_mae': [0.08081832528114319]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:19\u001b[0m 11s/step - loss: 0.0176 - mae: 0.0578\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0255 - mae: 0.0635 \n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0273 - mae: 0.0656\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0284 - mae: 0.0677\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0299 - mae: 0.0711\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0299 - mae: 0.0734\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0306 - mae: 0.0768\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0310 - mae: 0.0800\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0313 - mae: 0.0828\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0315 - mae: 0.0853\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0314 - mae: 0.0872\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0314 - mae: 0.0888\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0313 - mae: 0.0902\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0313 - mae: 0.0907\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0312 - mae: 0.0915\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0310 - mae: 0.0920\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0308 - mae: 0.0923\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0307 - mae: 0.0926\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0306 - mae: 0.0930\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0306 - mae: 0.0933\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0305 - mae: 0.0936\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0304 - mae: 0.0940\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - loss: 0.0304 - mae: 0.0942 - val_loss: 0.0240 - val_mae: 0.1012\n",
      "\n",
      "{'loss': [0.02917204424738884], 'mae': [0.10064038634300232], 'val_loss': [0.024035757407546043], 'val_mae': [0.10117676854133606]}\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:00\u001b[0m 13s/step - loss: 0.0334 - mae: 0.0627\n",
      "\u001b[1m 3/20\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0424 - mae: 0.1021 \n",
      "\u001b[1m 4/20\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0438 - mae: 0.1122\n",
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0442 - mae: 0.1175\n",
      "\u001b[1m 7/20\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0431 - mae: 0.1201\n",
      "\u001b[1m 8/20\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0423 - mae: 0.1198\n",
      "\u001b[1m10/20\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0406 - mae: 0.1178\n",
      "\u001b[1m11/20\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0398 - mae: 0.1165\n",
      "\u001b[1m13/20\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0385 - mae: 0.1143\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0373 - mae: 0.1124\n",
      "\u001b[1m16/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0367 - mae: 0.1114\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0358 - mae: 0.1096\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0349 - mae: 0.1081\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 155ms/step - loss: 0.0346 - mae: 0.1073 - val_loss: 0.0213 - val_mae: 0.0740\n",
      "\n",
      "{'loss': [0.027074946090579033], 'mae': [0.09330663830041885], 'val_loss': [0.021275123581290245], 'val_mae': [0.07403697073459625]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:02\u001b[0m 20s/step - loss: 0.0187 - mae: 0.0515\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0462 - mae: 0.1328  \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0493 - mae: 0.1355\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0491 - mae: 0.1308\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0480 - mae: 0.1263\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0466 - mae: 0.1233\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0451 - mae: 0.1206\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0437 - mae: 0.1179\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0430 - mae: 0.1168\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0418 - mae: 0.1146\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0411 - mae: 0.1136\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0401 - mae: 0.1120\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0393 - mae: 0.1108\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0385 - mae: 0.1097\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0379 - mae: 0.1085\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0376 - mae: 0.1080\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0371 - mae: 0.1069\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0368 - mae: 0.1060\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0365 - mae: 0.1052\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0363 - mae: 0.1045\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0361 - mae: 0.1039\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 109ms/step - loss: 0.0359 - mae: 0.1030 - val_loss: 0.0446 - val_mae: 0.1270\n",
      "\n",
      "{'loss': [0.03208591416478157], 'mae': [0.09237734973430634], 'val_loss': [0.044580958783626556], 'val_mae': [0.12704670429229736]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:33\u001b[0m 12s/step - loss: 0.0419 - mae: 0.0851\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0477 - mae: 0.1123 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0484 - mae: 0.1266\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0492 - mae: 0.1312\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0485 - mae: 0.1348\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0478 - mae: 0.1352\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0461 - mae: 0.1338\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0448 - mae: 0.1323\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0437 - mae: 0.1307\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0429 - mae: 0.1294\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0421 - mae: 0.1278\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0417 - mae: 0.1270\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0409 - mae: 0.1252\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0405 - mae: 0.1243\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0398 - mae: 0.1224\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0391 - mae: 0.1208\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0386 - mae: 0.1193\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0380 - mae: 0.1182\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0375 - mae: 0.1171\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0373 - mae: 0.1166\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0370 - mae: 0.1160\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0368 - mae: 0.1155\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0363 - mae: 0.1144\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0358 - mae: 0.1133\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 103ms/step - loss: 0.0356 - mae: 0.1128 - val_loss: 0.0389 - val_mae: 0.0920\n",
      "\n",
      "{'loss': [0.026740331202745438], 'mae': [0.09232056140899658], 'val_loss': [0.03889430686831474], 'val_mae': [0.09202750027179718]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:53\u001b[0m 12s/step - loss: 0.0317 - mae: 0.0729\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0295 - mae: 0.0984 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0282 - mae: 0.0995\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0284 - mae: 0.0998\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0291 - mae: 0.1022\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0293 - mae: 0.1039\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0295 - mae: 0.1044\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0299 - mae: 0.1047\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0304 - mae: 0.1048\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0306 - mae: 0.1046\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0308 - mae: 0.1041\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0307 - mae: 0.1037\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0306 - mae: 0.1032\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0305 - mae: 0.1028\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0303 - mae: 0.1023\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0302 - mae: 0.1020\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0301 - mae: 0.1018\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0300 - mae: 0.1013\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0298 - mae: 0.1007\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0296 - mae: 0.1000\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0293 - mae: 0.0994\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0291 - mae: 0.0988\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 103ms/step - loss: 0.0289 - mae: 0.0982 - val_loss: 0.0185 - val_mae: 0.0687\n",
      "\n",
      "{'loss': [0.025029728189110756], 'mae': [0.08661110699176788], 'val_loss': [0.018450843170285225], 'val_mae': [0.0687258392572403]}\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:49\u001b[0m 12s/step - loss: 0.0485 - mae: 0.0865\n",
      "\u001b[1m 3/20\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 205.8611 - mae: 6.3608\n",
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 190.2189 - mae: 5.8943\n",
      "\u001b[1m 7/20\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 168.6494 - mae: 5.2506\n",
      "\u001b[1m 9/20\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 150.6243 - mae: 4.7141\n",
      "\u001b[1m11/20\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 136.1104 - mae: 4.2830\n",
      "\u001b[1m13/20\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 124.3157 - mae: 3.9312\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 114.5717 - mae: 3.6393\n",
      "\u001b[1m16/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 110.3098 - mae: 3.5113\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 106.3892 - mae: 3.3936\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 102.7697 - mae: 3.2849\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 96.3335 - mae: 3.0916 \n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 149ms/step - loss: 93.5434 - mae: 3.0079 - val_loss: 0.0932 - val_mae: 0.2172\n",
      "\n",
      "{'loss': [37.741580963134766], 'mae': [1.3324106931686401], 'val_loss': [0.09320307523012161], 'val_mae': [0.21723376214504242]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:32\u001b[0m 12s/step - loss: 0.0524 - mae: 0.0852\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0418 - mae: 0.1052 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0403 - mae: 0.1063\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0391 - mae: 0.1055\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0382 - mae: 0.1066\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0378 - mae: 0.1074\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0371 - mae: 0.1073\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0364 - mae: 0.1068\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0360 - mae: 0.1066\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0354 - mae: 0.1060\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0352 - mae: 0.1057\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0346 - mae: 0.1048\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0341 - mae: 0.1037\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0336 - mae: 0.1028\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0331 - mae: 0.1018\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0327 - mae: 0.1009\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0322 - mae: 0.1002\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0318 - mae: 0.0995\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0314 - mae: 0.0988\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0312 - mae: 0.0984\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0310 - mae: 0.0980\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0306 - mae: 0.0972\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - loss: 0.0302 - mae: 0.0964 - val_loss: 0.0152 - val_mae: 0.0647\n",
      "\n",
      "{'loss': [0.023130755871534348], 'mae': [0.08146996796131134], 'val_loss': [0.015155180357396603], 'val_mae': [0.06474749743938446]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:24\u001b[0m 11s/step - loss: 0.0174 - mae: 0.0560\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0278 - mae: 0.0709 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0342 - mae: 0.0774\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0357 - mae: 0.0790\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0352 - mae: 0.0781\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0358 - mae: 0.0787\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0361 - mae: 0.0790\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0361 - mae: 0.0790\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0360 - mae: 0.0789\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0355 - mae: 0.0784\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0351 - mae: 0.0783\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0350 - mae: 0.0783\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0348 - mae: 0.0785\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0348 - mae: 0.0787\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0346 - mae: 0.0790\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0344 - mae: 0.0791\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0341 - mae: 0.0793\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0340 - mae: 0.0794\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0339 - mae: 0.0796\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0339 - mae: 0.0797\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0337 - mae: 0.0801\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0337 - mae: 0.0807\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0337 - mae: 0.0812\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0337 - mae: 0.0818\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0337 - mae: 0.0824\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 93ms/step - loss: 0.0337 - mae: 0.0827 - val_loss: 0.0415 - val_mae: 0.1279\n",
      "\n",
      "{'loss': [0.03425931930541992], 'mae': [0.09400478005409241], 'val_loss': [0.041463930159807205], 'val_mae': [0.12793080508708954]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 21s/step - loss: 0.0412 - mae: 0.0813\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0412 - mae: 0.0817 \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0395 - mae: 0.0797\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0395 - mae: 0.0808\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0391 - mae: 0.0815\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 578ms/step - loss: 0.0389 - mae: 0.0820 - val_loss: 0.0492 - val_mae: 0.1200\n",
      "\n",
      "{'loss': [0.03785506635904312], 'mae': [0.08448004722595215], 'val_loss': [0.04918744042515755], 'val_mae': [0.12001283466815948]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 12s/step - loss: 0.0306 - mae: 0.0651\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0611 - mae: 0.1428 \n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0652 - mae: 0.1564\n",
      "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0645 - mae: 0.1556\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0638 - mae: 0.1530\n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0630 - mae: 0.1496\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0617 - mae: 0.1456\n",
      "\u001b[1m 8/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0605 - mae: 0.1417\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0594 - mae: 0.1384\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0586 - mae: 0.1357\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 285ms/step - loss: 0.0579 - mae: 0.1334 - val_loss: 0.0554 - val_mae: 0.1120\n",
      "\n",
      "{'loss': [0.05123919993638992], 'mae': [0.11086220294237137], 'val_loss': [0.055351365357637405], 'val_mae': [0.11203913390636444]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 11s/step - loss: 0.0425 - mae: 0.0814\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0402 - mae: 0.0771\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0401 - mae: 0.0764\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0403 - mae: 0.0772\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0402 - mae: 0.0772\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 609ms/step - loss: 0.0401 - mae: 0.0772 - val_loss: 0.0550 - val_mae: 0.1107\n",
      "\n",
      "{'loss': [0.03973274305462837], 'mae': [0.07733001559972763], 'val_loss': [0.05499982088804245], 'val_mae': [0.11074969917535782]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:35\u001b[0m 12s/step - loss: 0.0729 - mae: 0.1240\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 5.5721 - mae: 1.2949 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 5.1462 - mae: 1.1998\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 4.5659 - mae: 1.0752\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 4.0810 - mae: 0.9706\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 3.6906 - mae: 0.8859\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 3.3730 - mae: 0.8166\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 3.2359 - mae: 0.7873\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 2.9962 - mae: 0.7362\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 2.7936 - mae: 0.6931\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 2.7036 - mae: 0.6739\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 2.5421 - mae: 0.6392\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2.4013 - mae: 0.6089\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.3373 - mae: 0.5952\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.2771 - mae: 0.5823\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 2.1667 - mae: 0.5587\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 2.1160 - mae: 0.5479\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.0223 - mae: 0.5279\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.9376 - mae: 0.5098\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.8606 - mae: 0.4933\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.8247 - mae: 0.4856\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.7574 - mae: 0.4712\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.6955 - mae: 0.4580\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 100ms/step - loss: 1.6391 - mae: 0.4460 - val_loss: 0.0269 - val_mae: 0.1114\n",
      "\n",
      "{'loss': [0.5396385192871094], 'mae': [0.21127864718437195], 'val_loss': [0.02694033645093441], 'val_mae': [0.1113801896572113]}\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:46\u001b[0m 15s/step - loss: 0.0599 - mae: 0.1091\n",
      "\u001b[1m 3/20\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 36132440.0000 - mae: 2991.1763\n",
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 33613276.0000 - mae: 2865.5076\n",
      "\u001b[1m 7/20\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 29877978.0000 - mae: 2584.7444\n",
      "\u001b[1m 9/20\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 26724514.0000 - mae: 2337.0154\n",
      "\u001b[1m11/20\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 24174122.0000 - mae: 2132.1641\n",
      "\u001b[1m13/20\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 22115008.0000 - mae: 1964.3474\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 20423236.0000 - mae: 1825.6127\n",
      "\u001b[1m16/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 19680378.0000 - mae: 1764.7439\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 19003994.0000 - mae: 1711.8799\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 18379808.0000 - mae: 1664.0486\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 17267408.0000 - mae: 1579.3549\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 155ms/step - loss: 16784828.0000 - mae: 1542.5815 - val_loss: 2169.7444 - val_mae: 44.4115\n",
      "\n",
      "{'loss': [7133194.5], 'mae': [807.1157836914062], 'val_loss': [2169.744384765625], 'val_mae': [44.4114875793457]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 11s/step - loss: 0.0314 - mae: 0.0639\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0340 - mae: 0.0774\n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0358 - mae: 0.0894\n",
      "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0372 - mae: 0.0991\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0378 - mae: 0.1057\n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0379 - mae: 0.1100\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0379 - mae: 0.1126\n",
      "\u001b[1m 8/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0376 - mae: 0.1140\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0372 - mae: 0.1145\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0369 - mae: 0.1145\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 353ms/step - loss: 0.0366 - mae: 0.1145 - val_loss: 0.0439 - val_mae: 0.1045\n",
      "\n",
      "{'loss': [0.033581532537937164], 'mae': [0.11482354253530502], 'val_loss': [0.04390372708439827], 'val_mae': [0.1045408546924591]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:55\u001b[0m 11s/step - loss: 0.0245 - mae: 0.0604\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0400 - mae: 0.0890 \n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0409 - mae: 0.0925\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0421 - mae: 0.0973\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0424 - mae: 0.0994\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0418 - mae: 0.1018\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0407 - mae: 0.1030\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0399 - mae: 0.1040\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0396 - mae: 0.1044\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0388 - mae: 0.1047\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0384 - mae: 0.1046\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0376 - mae: 0.1045\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0370 - mae: 0.1043\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0364 - mae: 0.1041\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0360 - mae: 0.1040\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0358 - mae: 0.1039\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0354 - mae: 0.1039\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0351 - mae: 0.1038\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0347 - mae: 0.1036\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0343 - mae: 0.1034\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0340 - mae: 0.1032\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0337 - mae: 0.1031\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0335 - mae: 0.1030\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 85ms/step - loss: 0.0333 - mae: 0.1029 - val_loss: 0.0242 - val_mae: 0.0937\n",
      "\n",
      "{'loss': [0.028386563062667847], 'mae': [0.10079474002122879], 'val_loss': [0.02419264428317547], 'val_mae': [0.09366990625858307]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 21s/step - loss: 0.0318 - mae: 0.0636\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0337 - mae: 0.0740 \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0342 - mae: 0.0832\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0344 - mae: 0.0902\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0344 - mae: 0.0950\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 546ms/step - loss: 0.0344 - mae: 0.0982 - val_loss: 0.0375 - val_mae: 0.1206\n",
      "\n",
      "{'loss': [0.034486450254917145], 'mae': [0.11422495543956757], 'val_loss': [0.037540681660175323], 'val_mae': [0.1206287071108818]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:49\u001b[0m 10s/step - loss: 0.0427 - mae: 0.0792\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0474 - mae: 0.0869 \n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0445 - mae: 0.0850\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0418 - mae: 0.0826\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0400 - mae: 0.0815\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0387 - mae: 0.0807\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0378 - mae: 0.0805\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0373 - mae: 0.0806\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0368 - mae: 0.0807\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0364 - mae: 0.0810\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0363 - mae: 0.0816\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0360 - mae: 0.0820\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0359 - mae: 0.0827\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0358 - mae: 0.0834\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.0358 - mae: 0.0841\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0358 - mae: 0.0849\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0359 - mae: 0.0857\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0358 - mae: 0.0865\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0357 - mae: 0.0871\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0357 - mae: 0.0877\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0356 - mae: 0.0884\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0355 - mae: 0.0890\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0354 - mae: 0.0896\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0353 - mae: 0.0901\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0352 - mae: 0.0906\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0351 - mae: 0.0911\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0350 - mae: 0.0915\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0349 - mae: 0.0919\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0348 - mae: 0.0923\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0347 - mae: 0.0927\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0346 - mae: 0.0931\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0346 - mae: 0.0935\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0346 - mae: 0.0939\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0345 - mae: 0.0942\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0345 - mae: 0.0946\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0344 - mae: 0.0949\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0344 - mae: 0.0952\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0344 - mae: 0.0954\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0343 - mae: 0.0957\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 130ms/step - loss: 0.0343 - mae: 0.0962 - val_loss: 0.0384 - val_mae: 0.1161\n",
      "\n",
      "{'loss': [0.03291868045926094], 'mae': [0.10603225976228714], 'val_loss': [0.038392841815948486], 'val_mae': [0.11612178385257721]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 11s/step - loss: 0.0410 - mae: 0.0807\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0418 - mae: 0.0964 \n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0418 - mae: 0.1083\n",
      "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0414 - mae: 0.1149\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0408 - mae: 0.1181\n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0396 - mae: 0.1185\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0385 - mae: 0.1179\n",
      "\u001b[1m 8/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0375 - mae: 0.1168\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0367 - mae: 0.1155\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0360 - mae: 0.1145\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 289ms/step - loss: 0.0354 - mae: 0.1136 - val_loss: 0.0200 - val_mae: 0.0747\n",
      "\n",
      "{'loss': [0.029784923419356346], 'mae': [0.10469666868448257], 'val_loss': [0.01997569017112255], 'val_mae': [0.07473228871822357]}\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:34\u001b[0m 14s/step - loss: 0.0321 - mae: 0.0681\n",
      "\u001b[1m 3/20\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0432 - mae: 0.1233 \n",
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0435 - mae: 0.1235\n",
      "\u001b[1m 7/20\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0428 - mae: 0.1202\n",
      "\u001b[1m 8/20\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0425 - mae: 0.1197\n",
      "\u001b[1m10/20\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0425 - mae: 0.1207\n",
      "\u001b[1m12/20\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0418 - mae: 0.1199\n",
      "\u001b[1m13/20\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0413 - mae: 0.1190\n",
      "\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0408 - mae: 0.1180\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0403 - mae: 0.1170\n",
      "\u001b[1m16/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0400 - mae: 0.1161\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0396 - mae: 0.1150\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0392 - mae: 0.1140\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0389 - mae: 0.1131\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0387 - mae: 0.1122\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 230ms/step - loss: 0.0385 - mae: 0.1114 - val_loss: 0.0415 - val_mae: 0.0999\n",
      "\n",
      "{'loss': [0.033733293414115906], 'mae': [0.09574944525957108], 'val_loss': [0.0415232889354229], 'val_mae': [0.09991531074047089]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 14s/step - loss: 0.0418 - mae: 0.0813\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0399 - mae: 0.0842\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0384 - mae: 0.0885\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0374 - mae: 0.0931\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0369 - mae: 0.0969\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 816ms/step - loss: 0.0365 - mae: 0.0995 - val_loss: 0.0380 - val_mae: 0.1308\n",
      "\n",
      "{'loss': [0.034712210297584534], 'mae': [0.11213216185569763], 'val_loss': [0.037962693721055984], 'val_mae': [0.13077227771282196]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:11\u001b[0m 16s/step - loss: 0.0225 - mae: 0.0652\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0982 - mae: 0.1959  \n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0989 - mae: 0.1949\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0955 - mae: 0.1882\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0923 - mae: 0.1813\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0891 - mae: 0.1750\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0866 - mae: 0.1697\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0845 - mae: 0.1652\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0826 - mae: 0.1611\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0811 - mae: 0.1578\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0796 - mae: 0.1547\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0780 - mae: 0.1517\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0765 - mae: 0.1492\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0736 - mae: 0.1452\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0711 - mae: 0.1425\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0700 - mae: 0.1414\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0679 - mae: 0.1392\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0670 - mae: 0.1382\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0652 - mae: 0.1363\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0635 - mae: 0.1343\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0628 - mae: 0.1336\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0616 - mae: 0.1322\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0610 - mae: 0.1315\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0604 - mae: 0.1308\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0598 - mae: 0.1302\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0592 - mae: 0.1296\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0587 - mae: 0.1290\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0577 - mae: 0.1280\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0572 - mae: 0.1275\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0568 - mae: 0.1271\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0559 - mae: 0.1263\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - loss: 0.0555 - mae: 0.1260 - val_loss: 0.0228 - val_mae: 0.1014\n",
      "\n",
      "{'loss': [0.04004134610295296], 'mae': [0.11178413033485413], 'val_loss': [0.022827371954917908], 'val_mae': [0.10143881291151047]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:52\u001b[0m 14s/step - loss: 0.0308 - mae: 0.0649\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 6.5151 - mae: 1.3113 \n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 7.2389 - mae: 1.4557\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 7.0631 - mae: 1.4290\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - loss: 6.6982 - mae: 1.3648\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - loss: 6.3112 - mae: 1.2960\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - loss: 5.9465 - mae: 1.2303\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - loss: 5.6143 - mae: 1.1690\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 5.3162 - mae: 1.1139\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 140ms/step - loss: 5.0486 - mae: 1.0639\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 4.8082 - mae: 1.0190\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 4.3954 - mae: 0.9423\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - loss: 4.2172 - mae: 0.9094\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 4.0544 - mae: 0.8790\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - loss: 3.9052 - mae: 0.8511\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - loss: 3.7677 - mae: 0.8251\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - loss: 3.6408 - mae: 0.8011\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - loss: 3.5231 - mae: 0.7787\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 3.4138 - mae: 0.7578\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 3.3120 - mae: 0.7385\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 3.2168 - mae: 0.7204\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - loss: 3.1276 - mae: 0.7033\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 3.0439 - mae: 0.6872\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 2.9652 - mae: 0.6719\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 2.8910 - mae: 0.6575\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 2.8209 - mae: 0.6440\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 2.7546 - mae: 0.6311\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 2.6918 - mae: 0.6189\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 2.6322 - mae: 0.6073\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 2.5756 - mae: 0.5962\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 2.5216 - mae: 0.5857\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 2.4702 - mae: 0.5756\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 2.3743 - mae: 0.5568\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 2.3294 - mae: 0.5481\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 2.2865 - mae: 0.5397\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 2.2453 - mae: 0.5318\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 2.2058 - mae: 0.5242\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 2.1322 - mae: 0.5100 - val_loss: 0.0410 - val_mae: 0.1500\n",
      "\n",
      "{'loss': [0.6981408596038818], 'mae': [0.23456813395023346], 'val_loss': [0.04095793142914772], 'val_mae': [0.14998026192188263]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:00\u001b[0m 13s/step - loss: 0.0389 - mae: 0.0953\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.0356 - mae: 0.0903\n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0336 - mae: 0.0887\n",
      "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0321 - mae: 0.0883\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0316 - mae: 0.0895\n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0311 - mae: 0.0904\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0308 - mae: 0.0916\n",
      "\u001b[1m 8/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0307 - mae: 0.0928\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0307 - mae: 0.0941\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0310 - mae: 0.0955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 378ms/step - loss: 0.0311 - mae: 0.0966 - val_loss: 0.0394 - val_mae: 0.1300\n",
      "\n",
      "{'loss': [0.03281500190496445], 'mae': [0.10762735456228256], 'val_loss': [0.039360567927360535], 'val_mae': [0.13003210723400116]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:34\u001b[0m 27s/step - loss: 0.0569 - mae: 0.0993\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 181585.8281 - mae: 174.1783\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 196717.9688 - mae: 188.7041\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 175533.0156 - mae: 168.4501\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 165280.2812 - mae: 158.6653\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 147608.0156 - mae: 141.8949\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 140111.1875 - mae: 134.7661\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 127306.7734 - mae: 122.5692\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 116817.4375 - mae: 112.5656\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 108079.4531 - mae: 104.2240\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 100686.4766 - mae: 97.1601 \n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 97399.3906 - mae: 94.0169 \n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 91499.9688 - mae: 88.3726\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 86352.2031 - mae: 83.4428\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 84015.3125 - mae: 81.2035\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 79744.7031 - mae: 77.1094\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 75936.0469 - mae: 73.4556\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 74181.3047 - mae: 71.7714\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 70932.3750 - mae: 68.6518\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 67988.3672 - mae: 65.8235\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 66617.0938 - mae: 64.5056\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 64053.1523 - mae: 62.0406\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 61701.6328 - mae: 59.7790\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 59543.7695 - mae: 57.7029\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 134ms/step - loss: 58541.8047 - mae: 56.7390 - val_loss: 0.0444 - val_mae: 0.1434\n",
      "\n",
      "{'loss': [18463.060546875], 'mae': [18.179697036743164], 'val_loss': [0.04438042268157005], 'val_mae': [0.14340783655643463]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 12s/step - loss: 0.0322 - mae: 0.0714\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0340 - mae: 0.0743\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0345 - mae: 0.0776\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0353 - mae: 0.0820\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0355 - mae: 0.0858\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 655ms/step - loss: 0.0356 - mae: 0.0883 - val_loss: 0.0436 - val_mae: 0.1472\n",
      "\n",
      "{'loss': [0.03628140315413475], 'mae': [0.10101670026779175], 'val_loss': [0.04356684163212776], 'val_mae': [0.14717021584510803]}\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:55\u001b[0m 12s/step - loss: 0.0331 - mae: 0.0697\n",
      "\u001b[1m 2/20\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0292 - mae: 0.0678 \n",
      "\u001b[1m 3/20\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0288 - mae: 0.0689\n",
      "\u001b[1m 4/20\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0285 - mae: 0.0698\n",
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0283 - mae: 0.0712\n",
      "\u001b[1m 6/20\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0280 - mae: 0.0724\n",
      "\u001b[1m 7/20\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0279 - mae: 0.0737\n",
      "\u001b[1m 8/20\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0283 - mae: 0.0754\n",
      "\u001b[1m 9/20\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0286 - mae: 0.0768\n",
      "\u001b[1m10/20\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0288 - mae: 0.0783\n",
      "\u001b[1m11/20\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0289 - mae: 0.0796\n",
      "\u001b[1m12/20\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0291 - mae: 0.0811\n",
      "\u001b[1m13/20\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0293 - mae: 0.0825\n",
      "\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0294 - mae: 0.0838\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0296 - mae: 0.0850\n",
      "\u001b[1m16/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0297 - mae: 0.0861\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0298 - mae: 0.0872\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0299 - mae: 0.0883\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0301 - mae: 0.0893\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0302 - mae: 0.0903\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 199ms/step - loss: 0.0303 - mae: 0.0911 - val_loss: 0.0359 - val_mae: 0.1255\n",
      "\n",
      "{'loss': [0.032255709171295166], 'mae': [0.10801789164543152], 'val_loss': [0.03594230115413666], 'val_mae': [0.12552691996097565]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:44\u001b[0m 12s/step - loss: 0.0241 - mae: 0.0582\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0269 - mae: 0.0842 \n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0271 - mae: 0.0892\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0268 - mae: 0.0894\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0282 - mae: 0.0904\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0292 - mae: 0.0909\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - loss: 0.0297 - mae: 0.0915\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0302 - mae: 0.0931 \n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0305 - mae: 0.0947\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0307 - mae: 0.0960\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.0309 - mae: 0.0971\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.0309 - mae: 0.0975\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 0.0309 - mae: 0.0977 \n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0309 - mae: 0.0976\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.0308 - mae: 0.0973\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0309 - mae: 0.0972\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 0.0309 - mae: 0.0970\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0310 - mae: 0.0967\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0309 - mae: 0.0964\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0310 - mae: 0.0961\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0310 - mae: 0.0958\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0310 - mae: 0.0955\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0310 - mae: 0.0953\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0311 - mae: 0.0952\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0312 - mae: 0.0951\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0312 - mae: 0.0950\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0313 - mae: 0.0951\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0314 - mae: 0.0951\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0314 - mae: 0.0952\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0314 - mae: 0.0953\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0314 - mae: 0.0954\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0314 - mae: 0.0955\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0314 - mae: 0.0955\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0313 - mae: 0.0955\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0313 - mae: 0.0955\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0312 - mae: 0.0954\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0312 - mae: 0.0954\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0311 - mae: 0.0953\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0311 - mae: 0.0953\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0310 - mae: 0.0952\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 154ms/step - loss: 0.0310 - mae: 0.0951 - val_loss: 0.0209 - val_mae: 0.0809\n",
      "\n",
      "{'loss': [0.02929704450070858], 'mae': [0.09277595579624176], 'val_loss': [0.02089887298643589], 'val_mae': [0.0808563381433487]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:58\u001b[0m 12s/step - loss: 0.0510 - mae: 0.0978\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.5718 - mae: 0.4268 \n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.6129 - mae: 0.4573\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.5493 - mae: 0.4154\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.5188 - mae: 0.3954\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.4654 - mae: 0.3602\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.4231 - mae: 0.3331\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.3890 - mae: 0.3116\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.3745 - mae: 0.3028\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.3613 - mae: 0.2948\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.3493 - mae: 0.2875\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.3279 - mae: 0.2746\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.3185 - mae: 0.2689\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.3015 - mae: 0.2584\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.2867 - mae: 0.2492\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2738 - mae: 0.2411\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.2622 - mae: 0.2339\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.2520 - mae: 0.2276\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.2428 - mae: 0.2219\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2344 - mae: 0.2166\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2268 - mae: 0.2119\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2198 - mae: 0.2078\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2134 - mae: 0.2039\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 109ms/step - loss: 0.2075 - mae: 0.2005 - val_loss: 0.0466 - val_mae: 0.1382\n",
      "\n",
      "{'loss': [0.0930437296628952], 'mae': [0.13271614909172058], 'val_loss': [0.046617355197668076], 'val_mae': [0.1381557136774063]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:12\u001b[0m 15s/step - loss: 0.0219 - mae: 0.0605\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - loss: 0.0549 - mae: 0.1371\n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.0579 - mae: 0.1491\n",
      "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0601 - mae: 0.1525\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0620 - mae: 0.1537\n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0623 - mae: 0.1520\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0619 - mae: 0.1494\n",
      "\u001b[1m 8/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0613 - mae: 0.1464\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0604 - mae: 0.1431\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0593 - mae: 0.1399\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 407ms/step - loss: 0.0585 - mae: 0.1372 - val_loss: 0.0536 - val_mae: 0.1129\n",
      "\n",
      "{'loss': [0.0500132218003273], 'mae': [0.1110779270529747], 'val_loss': [0.0536167211830616], 'val_mae': [0.11290409415960312]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:54\u001b[0m 14s/step - loss: 0.0468 - mae: 0.0907\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0398 - mae: 0.0987 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0407 - mae: 0.1107\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0410 - mae: 0.1177\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0396 - mae: 0.1188\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0391 - mae: 0.1185\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0386 - mae: 0.1181\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0376 - mae: 0.1165\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0368 - mae: 0.1147\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0363 - mae: 0.1139\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0355 - mae: 0.1124\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0351 - mae: 0.1116\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0344 - mae: 0.1100\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0340 - mae: 0.1093\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0333 - mae: 0.1078\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0328 - mae: 0.1066\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0325 - mae: 0.1060\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0320 - mae: 0.1049\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0318 - mae: 0.1044\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0316 - mae: 0.1039\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0314 - mae: 0.1034\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0310 - mae: 0.1025\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0306 - mae: 0.1017\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0305 - mae: 0.1013\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0302 - mae: 0.1006\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 130ms/step - loss: 0.0299 - mae: 0.0999 - val_loss: 0.0177 - val_mae: 0.0774\n",
      "\n",
      "{'loss': [0.024633092805743217], 'mae': [0.08769479393959045], 'val_loss': [0.017748091369867325], 'val_mae': [0.07744693756103516]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:35\u001b[0m 13s/step - loss: 0.0616 - mae: 0.1040\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0574 - mae: 0.1333 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0550 - mae: 0.1442\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0528 - mae: 0.1436\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0487 - mae: 0.1385\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0471 - mae: 0.1358\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0445 - mae: 0.1307\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0435 - mae: 0.1284\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0417 - mae: 0.1250\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0410 - mae: 0.1236\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0398 - mae: 0.1213\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0392 - mae: 0.1203\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0381 - mae: 0.1181\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0371 - mae: 0.1162\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0366 - mae: 0.1152\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0357 - mae: 0.1133\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0353 - mae: 0.1123\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0345 - mae: 0.1105\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0338 - mae: 0.1088\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0335 - mae: 0.1080\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0330 - mae: 0.1066\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0328 - mae: 0.1060\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0324 - mae: 0.1049\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0322 - mae: 0.1044\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0320 - mae: 0.1039\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0318 - mae: 0.1034\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 125ms/step - loss: 0.0315 - mae: 0.1026 - val_loss: 0.0204 - val_mae: 0.0794\n",
      "\n",
      "{'loss': [0.025344543159008026], 'mae': [0.086075060069561], 'val_loss': [0.02041413076221943], 'val_mae': [0.07936820387840271]}\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:45\u001b[0m 12s/step - loss: 0.0778 - mae: 0.1238\n",
      "\u001b[1m 2/20\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0726 - mae: 0.1497 \n",
      "\u001b[1m 3/20\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0662 - mae: 0.1512\n",
      "\u001b[1m 4/20\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0621 - mae: 0.1484\n",
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0592 - mae: 0.1443\n",
      "\u001b[1m 6/20\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0563 - mae: 0.1397\n",
      "\u001b[1m 7/20\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0545 - mae: 0.1364\n",
      "\u001b[1m 8/20\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0533 - mae: 0.1338\n",
      "\u001b[1m 9/20\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0521 - mae: 0.1317\n",
      "\u001b[1m10/20\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0511 - mae: 0.1301\n",
      "\u001b[1m11/20\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0501 - mae: 0.1288\n",
      "\u001b[1m12/20\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0492 - mae: 0.1278\n",
      "\u001b[1m13/20\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0482 - mae: 0.1268\n",
      "\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0474 - mae: 0.1258\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0465 - mae: 0.1247\n",
      "\u001b[1m16/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0457 - mae: 0.1236\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0450 - mae: 0.1226\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0444 - mae: 0.1215\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0438 - mae: 0.1205\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0434 - mae: 0.1196\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 247ms/step - loss: 0.0429 - mae: 0.1187 - val_loss: 0.0384 - val_mae: 0.0970\n",
      "\n",
      "{'loss': [0.03404366597533226], 'mae': [0.10181522369384766], 'val_loss': [0.0383605994284153], 'val_mae': [0.09702388942241669]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 26s/step - loss: 0.0318 - mae: 0.0617\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.0338 - mae: 0.0723\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0349 - mae: 0.0803\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0355 - mae: 0.0867\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0355 - mae: 0.0913\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 700ms/step - loss: 0.0355 - mae: 0.0943 - val_loss: 0.0424 - val_mae: 0.1324\n",
      "\n",
      "{'loss': [0.0356990322470665], 'mae': [0.10969440639019012], 'val_loss': [0.04239257052540779], 'val_mae': [0.13237087428569794]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:42\u001b[0m 12s/step - loss: 0.0128 - mae: 0.0319\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0386 - mae: 0.1087 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0439 - mae: 0.1176\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0442 - mae: 0.1181\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0435 - mae: 0.1177\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0431 - mae: 0.1174\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0427 - mae: 0.1169\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0416 - mae: 0.1154\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0412 - mae: 0.1150\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0407 - mae: 0.1144\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0401 - mae: 0.1141\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0397 - mae: 0.1139\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0394 - mae: 0.1136\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0392 - mae: 0.1133\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0389 - mae: 0.1130\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0384 - mae: 0.1123\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0382 - mae: 0.1120\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0378 - mae: 0.1113\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0374 - mae: 0.1107\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0372 - mae: 0.1104\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0370 - mae: 0.1101\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0367 - mae: 0.1096\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0365 - mae: 0.1093\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0362 - mae: 0.1089\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0359 - mae: 0.1086\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - loss: 0.0357 - mae: 0.1084 - val_loss: 0.0295 - val_mae: 0.1101\n",
      "\n",
      "{'loss': [0.030295344069600105], 'mae': [0.10251922160387039], 'val_loss': [0.029480649158358574], 'val_mae': [0.11008700728416443]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:43\u001b[0m 12s/step - loss: 0.0547 - mae: 0.0937\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0514 - mae: 0.0915 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0483 - mae: 0.0913\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0454 - mae: 0.0919\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0444 - mae: 0.0926\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0435 - mae: 0.0934\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0425 - mae: 0.0940\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0417 - mae: 0.0947\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0410 - mae: 0.0953\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0403 - mae: 0.0959\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0396 - mae: 0.0964\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0390 - mae: 0.0968\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0382 - mae: 0.0978\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0381 - mae: 0.0985\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0378 - mae: 0.0997\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0374 - mae: 0.1006\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0372 - mae: 0.1010\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0370 - mae: 0.1013\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0366 - mae: 0.1017\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0362 - mae: 0.1020\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0359 - mae: 0.1023\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0356 - mae: 0.1025\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0355 - mae: 0.1026\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0353 - mae: 0.1026\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0351 - mae: 0.1027\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0348 - mae: 0.1026\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0345 - mae: 0.1026\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - loss: 0.0344 - mae: 0.1026 - val_loss: 0.0197 - val_mae: 0.0810\n",
      "\n",
      "{'loss': [0.029796339571475983], 'mae': [0.10203614085912704], 'val_loss': [0.019681083038449287], 'val_mae': [0.08097967505455017]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:00\u001b[0m 13s/step - loss: 0.0315 - mae: 0.0666\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0387 - mae: 0.0894\n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0400 - mae: 0.1036 \n",
      "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0396 - mae: 0.1110\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0395 - mae: 0.1151\n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0387 - mae: 0.1162\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.0382 - mae: 0.1166\n",
      "\u001b[1m 8/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0376 - mae: 0.1161\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0371 - mae: 0.1154\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0368 - mae: 0.1146\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 355ms/step - loss: 0.0365 - mae: 0.1140 - val_loss: 0.0324 - val_mae: 0.1049\n",
      "\n",
      "{'loss': [0.03348974138498306], 'mae': [0.10800551623106003], 'val_loss': [0.03243071585893631], 'val_mae': [0.1049414649605751]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:39\u001b[0m 12s/step - loss: 0.0062 - mae: 0.0280\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0212 - mae: 0.0794 \n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0232 - mae: 0.0832\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0252 - mae: 0.0859\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0268 - mae: 0.0884\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0286 - mae: 0.0923\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0302 - mae: 0.0971\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0303 - mae: 0.0978\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0303 - mae: 0.0979\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0302 - mae: 0.0974\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0305 - mae: 0.0973\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0307 - mae: 0.0972\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0311 - mae: 0.0968\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0312 - mae: 0.0967\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0313 - mae: 0.0965\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0314 - mae: 0.0963\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0314 - mae: 0.0961\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0315 - mae: 0.0960\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0315 - mae: 0.0960\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0315 - mae: 0.0960\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0315 - mae: 0.0962\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0315 - mae: 0.0963\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0314 - mae: 0.0964\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0313 - mae: 0.0964\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0312 - mae: 0.0963\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0311 - mae: 0.0962\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0310 - mae: 0.0960\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0308 - mae: 0.0957\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 130ms/step - loss: 0.0307 - mae: 0.0955 - val_loss: 0.0140 - val_mae: 0.0692\n",
      "\n",
      "{'loss': [0.028000762686133385], 'mae': [0.09074902534484863], 'val_loss': [0.01401388831436634], 'val_mae': [0.06917206943035126]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:35\u001b[0m 12s/step - loss: 0.0613 - mae: 0.1012\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0542 - mae: 0.1078 \n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0484 - mae: 0.1164\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0466 - mae: 0.1183\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0458 - mae: 0.1204\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0447 - mae: 0.1208\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0437 - mae: 0.1208\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0421 - mae: 0.1199\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0414 - mae: 0.1192\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0400 - mae: 0.1173\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0393 - mae: 0.1161\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0386 - mae: 0.1149\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0380 - mae: 0.1138\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0374 - mae: 0.1127\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0364 - mae: 0.1108\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0356 - mae: 0.1091\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0348 - mae: 0.1077\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0341 - mae: 0.1064\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0339 - mae: 0.1058\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0336 - mae: 0.1052\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0333 - mae: 0.1047\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0330 - mae: 0.1041\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0325 - mae: 0.1030\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0320 - mae: 0.1020\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0315 - mae: 0.1011\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0313 - mae: 0.1006\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0311 - mae: 0.1002\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0309 - mae: 0.0997\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0305 - mae: 0.0989\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 127ms/step - loss: 0.0303 - mae: 0.0985 - val_loss: 0.0134 - val_mae: 0.0819\n",
      "\n",
      "{'loss': [0.0233025960624218], 'mae': [0.08331210911273956], 'val_loss': [0.013351299799978733], 'val_mae': [0.08194134384393692]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:43\u001b[0m 12s/step - loss: 0.0631 - mae: 0.1083\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0570 - mae: 0.1139 \n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0519 - mae: 0.1248\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0515 - mae: 0.1312\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0494 - mae: 0.1319\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0483 - mae: 0.1312\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0472 - mae: 0.1303\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0464 - mae: 0.1296\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0458 - mae: 0.1288\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0449 - mae: 0.1275\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0444 - mae: 0.1266\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0440 - mae: 0.1257\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0435 - mae: 0.1247\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0430 - mae: 0.1237\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0421 - mae: 0.1218\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0412 - mae: 0.1199\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0405 - mae: 0.1185\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0397 - mae: 0.1171\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0394 - mae: 0.1165\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0387 - mae: 0.1153\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0383 - mae: 0.1148\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0380 - mae: 0.1142\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0377 - mae: 0.1136\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0374 - mae: 0.1130\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0367 - mae: 0.1119\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0365 - mae: 0.1114\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0362 - mae: 0.1108\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0359 - mae: 0.1103\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0356 - mae: 0.1097\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - loss: 0.0351 - mae: 0.1088 - val_loss: 0.0132 - val_mae: 0.0709\n",
      "\n",
      "{'loss': [0.025228243321180344], 'mae': [0.08974393457174301], 'val_loss': [0.013234424404799938], 'val_mae': [0.07094138860702515]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:39\u001b[0m 12s/step - loss: 0.0452 - mae: 0.0770\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0353 - mae: 0.0848 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0341 - mae: 0.0887\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0335 - mae: 0.0900\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0331 - mae: 0.0914\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0326 - mae: 0.0924\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0325 - mae: 0.0955\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0324 - mae: 0.0971\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0324 - mae: 0.0976\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0322 - mae: 0.0981\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0320 - mae: 0.0980\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0317 - mae: 0.0978\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0314 - mae: 0.0979\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0313 - mae: 0.0982\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0311 - mae: 0.0985\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0310 - mae: 0.0986\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0309 - mae: 0.0987\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0308 - mae: 0.0987\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0307 - mae: 0.0986\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0306 - mae: 0.0986\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0304 - mae: 0.0985\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0303 - mae: 0.0983\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0301 - mae: 0.0981\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0298 - mae: 0.0977\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0296 - mae: 0.0973\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0295 - mae: 0.0972\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0293 - mae: 0.0968\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 126ms/step - loss: 0.0291 - mae: 0.0965 - val_loss: 0.0173 - val_mae: 0.0666\n",
      "\n",
      "{'loss': [0.025794101879000664], 'mae': [0.0909484401345253], 'val_loss': [0.017279701307415962], 'val_mae': [0.0666472390294075]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:43\u001b[0m 12s/step - loss: 0.0040 - mae: 0.0370\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0278 - mae: 0.0732 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0329 - mae: 0.0865\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0341 - mae: 0.0944\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0343 - mae: 0.0971\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0345 - mae: 0.0994\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0349 - mae: 0.1015\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.0351 - mae: 0.1032\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0353 - mae: 0.1045\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0353 - mae: 0.1055\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0353 - mae: 0.1061\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0352 - mae: 0.1065\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0351 - mae: 0.1069\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0350 - mae: 0.1075\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0350 - mae: 0.1080\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0349 - mae: 0.1081\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0348 - mae: 0.1083\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0347 - mae: 0.1084\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0346 - mae: 0.1084\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0342 - mae: 0.1081\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0339 - mae: 0.1077\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0335 - mae: 0.1073\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0332 - mae: 0.1067\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0329 - mae: 0.1062\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0326 - mae: 0.1057\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0324 - mae: 0.1054\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0323 - mae: 0.1051\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0321 - mae: 0.1049\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0320 - mae: 0.1046\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 122ms/step - loss: 0.0319 - mae: 0.1044 - val_loss: 0.0192 - val_mae: 0.0986\n",
      "\n",
      "{'loss': [0.027013862505555153], 'mae': [0.0954408198595047], 'val_loss': [0.019163019955158234], 'val_mae': [0.09863566607236862]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:05\u001b[0m 26s/step - loss: 0.0543 - mae: 0.0973\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0462 - mae: 0.1011  \n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0432 - mae: 0.1056\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0412 - mae: 0.1082\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0396 - mae: 0.1090\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0378 - mae: 0.1077\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0363 - mae: 0.1060\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0350 - mae: 0.1041\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0342 - mae: 0.1028\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0327 - mae: 0.1005\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0321 - mae: 0.0997\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0315 - mae: 0.0988\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0311 - mae: 0.0981\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0303 - mae: 0.0966\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0300 - mae: 0.0959\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0293 - mae: 0.0946\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0290 - mae: 0.0941\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0288 - mae: 0.0937\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0286 - mae: 0.0933\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0283 - mae: 0.0927\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0281 - mae: 0.0924\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0280 - mae: 0.0922\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0280 - mae: 0.0919\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0279 - mae: 0.0918\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0279 - mae: 0.0916\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0278 - mae: 0.0915\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0278 - mae: 0.0914\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0278 - mae: 0.0914\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0277 - mae: 0.0913\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0277 - mae: 0.0913\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0276 - mae: 0.0912\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0276 - mae: 0.0912\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0275 - mae: 0.0911\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0274 - mae: 0.0909\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 141ms/step - loss: 0.0273 - mae: 0.0907 - val_loss: 0.0256 - val_mae: 0.0801\n",
      "\n",
      "{'loss': [0.0249375868588686], 'mae': [0.0871523916721344], 'val_loss': [0.02561417780816555], 'val_mae': [0.08007711172103882]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:46\u001b[0m 12s/step - loss: 0.0609 - mae: 0.0987\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.1054 - mae: 0.2035 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0941 - mae: 0.1889\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0900 - mae: 0.1820\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0866 - mae: 0.1760\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0849 - mae: 0.1719\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0832 - mae: 0.1680\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0811 - mae: 0.1636\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0792 - mae: 0.1598\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0773 - mae: 0.1561\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0736 - mae: 0.1492\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0720 - mae: 0.1463\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0690 - mae: 0.1414\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0666 - mae: 0.1381\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0646 - mae: 0.1359\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0637 - mae: 0.1349\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0619 - mae: 0.1330\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0604 - mae: 0.1313\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0591 - mae: 0.1297\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0585 - mae: 0.1290\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0573 - mae: 0.1276\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0568 - mae: 0.1270\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0562 - mae: 0.1264\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0557 - mae: 0.1259\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0547 - mae: 0.1248\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0543 - mae: 0.1244\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0538 - mae: 0.1239\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0534 - mae: 0.1234\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 131ms/step - loss: 0.0525 - mae: 0.1224 - val_loss: 0.0182 - val_mae: 0.0822\n",
      "\n",
      "{'loss': [0.035981982946395874], 'mae': [0.10416917502880096], 'val_loss': [0.018172914162278175], 'val_mae': [0.08221975713968277]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:41\u001b[0m 12s/step - loss: 0.0406 - mae: 0.0727\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0319 - mae: 0.0751 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0327 - mae: 0.0860\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0331 - mae: 0.0912\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0336 - mae: 0.0987\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0334 - mae: 0.1021\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0331 - mae: 0.1027\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0328 - mae: 0.1028\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0326 - mae: 0.1029\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0323 - mae: 0.1027\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0321 - mae: 0.1023\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0318 - mae: 0.1018\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0316 - mae: 0.1014\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0314 - mae: 0.1012\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0313 - mae: 0.1011\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0311 - mae: 0.1010\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0310 - mae: 0.1007\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0308 - mae: 0.1005\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0307 - mae: 0.1003\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0306 - mae: 0.1001\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0305 - mae: 0.0999\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0304 - mae: 0.0997\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0304 - mae: 0.0995\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0303 - mae: 0.0993\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0301 - mae: 0.0989\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0299 - mae: 0.0985\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0298 - mae: 0.0984\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0297 - mae: 0.0982\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0297 - mae: 0.0980\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0296 - mae: 0.0979\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0295 - mae: 0.0977\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 131ms/step - loss: 0.0294 - mae: 0.0975 - val_loss: 0.0168 - val_mae: 0.0796\n",
      "\n",
      "{'loss': [0.026282494887709618], 'mae': [0.09093526005744934], 'val_loss': [0.01679748296737671], 'val_mae': [0.07959137111902237]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:09\u001b[0m 13s/step - loss: 0.0385 - mae: 0.0679\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0466 - mae: 0.1238 \n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0479 - mae: 0.1270\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0476 - mae: 0.1266\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0466 - mae: 0.1236\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0462 - mae: 0.1222\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0458 - mae: 0.1211\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0456 - mae: 0.1207\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0456 - mae: 0.1212\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0456 - mae: 0.1218\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0454 - mae: 0.1221\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0451 - mae: 0.1222\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0448 - mae: 0.1220\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0443 - mae: 0.1215\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0441 - mae: 0.1212\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0439 - mae: 0.1207\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0436 - mae: 0.1201\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0430 - mae: 0.1190\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0424 - mae: 0.1177\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0421 - mae: 0.1171\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0419 - mae: 0.1166\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0417 - mae: 0.1161\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0414 - mae: 0.1157\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0412 - mae: 0.1153\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0410 - mae: 0.1149\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0408 - mae: 0.1145\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0406 - mae: 0.1142\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0404 - mae: 0.1139\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0400 - mae: 0.1132\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0398 - mae: 0.1129\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0396 - mae: 0.1126\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0394 - mae: 0.1122\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 136ms/step - loss: 0.0391 - mae: 0.1116 - val_loss: 0.0232 - val_mae: 0.0751\n",
      "\n",
      "{'loss': [0.03170732781291008], 'mae': [0.09939658641815186], 'val_loss': [0.02315925993025303], 'val_mae': [0.07511425763368607]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:56\u001b[0m 12s/step - loss: 0.0053 - mae: 0.0293\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0088 - mae: 0.0478 \n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0122 - mae: 0.0582\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0149 - mae: 0.0648\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0169 - mae: 0.0711\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0170 - mae: 0.0724\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.0169 - mae: 0.0729\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0171 - mae: 0.0733\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.0171 - mae: 0.0732\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0170 - mae: 0.0728\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0173 - mae: 0.0728\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0177 - mae: 0.0731\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0185 - mae: 0.0737\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0191 - mae: 0.0747\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0197 - mae: 0.0759\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0199 - mae: 0.0765\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0201 - mae: 0.0769\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0205 - mae: 0.0777\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0207 - mae: 0.0780\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0208 - mae: 0.0782\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0210 - mae: 0.0784\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0211 - mae: 0.0786\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0214 - mae: 0.0788\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0215 - mae: 0.0790\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0215 - mae: 0.0791\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0217 - mae: 0.0793\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0218 - mae: 0.0793\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0218 - mae: 0.0794\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0219 - mae: 0.0795\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0219 - mae: 0.0796\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0220 - mae: 0.0796\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0220 - mae: 0.0796\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 133ms/step - loss: 0.0221 - mae: 0.0797 - val_loss: 0.0200 - val_mae: 0.0836\n",
      "\n",
      "{'loss': [0.024150390177965164], 'mae': [0.0820436105132103], 'val_loss': [0.01999763213098049], 'val_mae': [0.08361319452524185]}\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:45\u001b[0m 12s/step - loss: 0.0290 - mae: 0.0622\n",
      "\u001b[1m 2/20\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0348 - mae: 0.0733 \n",
      "\u001b[1m 3/20\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0354 - mae: 0.0759\n",
      "\u001b[1m 4/20\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0360 - mae: 0.0779\n",
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0364 - mae: 0.0802\n",
      "\u001b[1m 6/20\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0367 - mae: 0.0822\n",
      "\u001b[1m 7/20\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0367 - mae: 0.0840\n",
      "\u001b[1m 8/20\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0369 - mae: 0.0860 \n",
      "\u001b[1m 9/20\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0369 - mae: 0.0878\n",
      "\u001b[1m10/20\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0369 - mae: 0.0895\n",
      "\u001b[1m11/20\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0368 - mae: 0.0911\n",
      "\u001b[1m12/20\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0367 - mae: 0.0925\n",
      "\u001b[1m13/20\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0365 - mae: 0.0938\n",
      "\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0364 - mae: 0.0949\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0363 - mae: 0.0960\n",
      "\u001b[1m16/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0362 - mae: 0.0970\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0362 - mae: 0.0979\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0361 - mae: 0.0987\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0360 - mae: 0.0993\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 215ms/step - loss: 0.0357 - mae: 0.1003 - val_loss: 0.0347 - val_mae: 0.1106\n",
      "\n",
      "{'loss': [0.033307284116744995], 'mae': [0.11000743508338928], 'val_loss': [0.03472510352730751], 'val_mae': [0.11062274873256683]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:54\u001b[0m 12s/step - loss: 0.1098 - mae: 0.1758\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0829 - mae: 0.1471 \n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0780 - mae: 0.1440\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0740 - mae: 0.1421\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0714 - mae: 0.1419\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0687 - mae: 0.1412\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.0662 - mae: 0.1408\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0643 - mae: 0.1405\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0624 - mae: 0.1401\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0607 - mae: 0.1395\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0592 - mae: 0.1389\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0565 - mae: 0.1371\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0553 - mae: 0.1361\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0533 - mae: 0.1343\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0515 - mae: 0.1322\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0507 - mae: 0.1312\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0499 - mae: 0.1303\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0492 - mae: 0.1294\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0485 - mae: 0.1285\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0472 - mae: 0.1269\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0460 - mae: 0.1254\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0450 - mae: 0.1241\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0441 - mae: 0.1229\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0432 - mae: 0.1218\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0425 - mae: 0.1208\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0418 - mae: 0.1198\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0412 - mae: 0.1188\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 128ms/step - loss: 0.0406 - mae: 0.1179 - val_loss: 0.0193 - val_mae: 0.0793\n",
      "\n",
      "{'loss': [0.029142189770936966], 'mae': [0.10063135623931885], 'val_loss': [0.019273055717349052], 'val_mae': [0.07929084450006485]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 12s/step - loss: 0.0435 - mae: 0.0814\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - loss: 0.0435 - mae: 0.0839\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - loss: 0.0421 - mae: 0.0836\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - loss: 0.0411 - mae: 0.0840\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 0.0403 - mae: 0.0846\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 747ms/step - loss: 0.0398 - mae: 0.0851 - val_loss: 0.0456 - val_mae: 0.1227\n",
      "\n",
      "{'loss': [0.037058278918266296], 'mae': [0.08717412501573563], 'val_loss': [0.04561661183834076], 'val_mae': [0.12269966304302216]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:42\u001b[0m 12s/step - loss: 0.0268 - mae: 0.0615\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0290 - mae: 0.0955 \n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0279 - mae: 0.0960\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0268 - mae: 0.0938\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0266 - mae: 0.0922\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0268 - mae: 0.0913\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0271 - mae: 0.0895\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0270 - mae: 0.0886\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0272 - mae: 0.0883\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0276 - mae: 0.0894\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0278 - mae: 0.0908\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0279 - mae: 0.0920\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0280 - mae: 0.0925\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0280 - mae: 0.0930\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0280 - mae: 0.0936\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0280 - mae: 0.0937\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0279 - mae: 0.0938\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0277 - mae: 0.0937\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0276 - mae: 0.0936\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0274 - mae: 0.0933\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0272 - mae: 0.0930\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0270 - mae: 0.0927\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0268 - mae: 0.0924\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0267 - mae: 0.0922\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0267 - mae: 0.0921\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0266 - mae: 0.0919\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 122ms/step - loss: 0.0265 - mae: 0.0917 - val_loss: 0.0194 - val_mae: 0.0735\n",
      "\n",
      "{'loss': [0.024122990667819977], 'mae': [0.08744556456804276], 'val_loss': [0.019429095089435577], 'val_mae': [0.07347747683525085]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:45\u001b[0m 12s/step - loss: 0.0374 - mae: 0.0733\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0347 - mae: 0.0762 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0312 - mae: 0.0788\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0309 - mae: 0.0809\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0307 - mae: 0.0829\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0309 - mae: 0.0869\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0310 - mae: 0.0885\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0310 - mae: 0.0910\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0310 - mae: 0.0930\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0309 - mae: 0.0937\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0308 - mae: 0.0942\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0307 - mae: 0.0946\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0305 - mae: 0.0947\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0303 - mae: 0.0951\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0300 - mae: 0.0952\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0298 - mae: 0.0952\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0296 - mae: 0.0952\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0295 - mae: 0.0951\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0294 - mae: 0.0951\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0294 - mae: 0.0951\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0293 - mae: 0.0951\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0292 - mae: 0.0952\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0292 - mae: 0.0953\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0291 - mae: 0.0954\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0290 - mae: 0.0955\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0289 - mae: 0.0955\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0288 - mae: 0.0956\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0288 - mae: 0.0956\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 132ms/step - loss: 0.0287 - mae: 0.0957 - val_loss: 0.0314 - val_mae: 0.0867\n",
      "\n",
      "{'loss': [0.026915865018963814], 'mae': [0.09663430601358414], 'val_loss': [0.03141025826334953], 'val_mae': [0.0866706594824791]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:35\u001b[0m 31s/step - loss: 0.0214 - mae: 0.0543\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0320 - mae: 0.0779\n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - loss: 0.0346 - mae: 0.0922\n",
      "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0352 - mae: 0.1005\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0354 - mae: 0.1054\n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0352 - mae: 0.1080\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0348 - mae: 0.1091\n",
      "\u001b[1m 8/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0344 - mae: 0.1094\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0340 - mae: 0.1094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0335 - mae: 0.1091\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 390ms/step - loss: 0.0332 - mae: 0.1089 - val_loss: 0.0187 - val_mae: 0.0880\n",
      "\n",
      "{'loss': [0.029680022969841957], 'mae': [0.1064559742808342], 'val_loss': [0.018725408241152763], 'val_mae': [0.08800161629915237]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:39\u001b[0m 12s/step - loss: 0.0255 - mae: 0.0564\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0220 - mae: 0.0655 \n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0221 - mae: 0.0695\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0243 - mae: 0.0739\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0253 - mae: 0.0762\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - loss: 0.0268 - mae: 0.0790\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.0275 - mae: 0.0811\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0282 - mae: 0.0835\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0288 - mae: 0.0876 \n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0287 - mae: 0.0898\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0286 - mae: 0.0901\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0285 - mae: 0.0904\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0288 - mae: 0.0908\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0290 - mae: 0.0911\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0292 - mae: 0.0913\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0294 - mae: 0.0915\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0294 - mae: 0.0917\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0295 - mae: 0.0918\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0295 - mae: 0.0920\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0296 - mae: 0.0926\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0296 - mae: 0.0930\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0297 - mae: 0.0934\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0298 - mae: 0.0936\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0298 - mae: 0.0937\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0298 - mae: 0.0938\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0298 - mae: 0.0938\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0298 - mae: 0.0938\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0297 - mae: 0.0938\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0297 - mae: 0.0938\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0297 - mae: 0.0938\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0296 - mae: 0.0937\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0296 - mae: 0.0937\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 141ms/step - loss: 0.0295 - mae: 0.0936 - val_loss: 0.0161 - val_mae: 0.0797\n",
      "\n",
      "{'loss': [0.027873631566762924], 'mae': [0.09178095310926437], 'val_loss': [0.01612800732254982], 'val_mae': [0.07969801127910614]}\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:43\u001b[0m 12s/step - loss: 0.0531 - mae: 0.0924\n",
      "\u001b[1m 2/20\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0468 - mae: 0.0907 \n",
      "\u001b[1m 3/20\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 150ms/step - loss: 0.0444 - mae: 0.0935\n",
      "\u001b[1m 4/20\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 0.0426 - mae: 0.0963\n",
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - loss: 0.0407 - mae: 0.0983\n",
      "\u001b[1m 6/20\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.0396 - mae: 0.1006\n",
      "\u001b[1m 7/20\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 0.0385 - mae: 0.1021\n",
      "\u001b[1m 8/20\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 0.0379 - mae: 0.1035\n",
      "\u001b[1m 9/20\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.0371 - mae: 0.1042\n",
      "\u001b[1m10/20\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.0364 - mae: 0.1046\n",
      "\u001b[1m11/20\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0358 - mae: 0.1048\n",
      "\u001b[1m12/20\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.0355 - mae: 0.1050\n",
      "\u001b[1m13/20\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 0.0352 - mae: 0.1052\n",
      "\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0351 - mae: 0.1054\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0349 - mae: 0.1054\n",
      "\u001b[1m16/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.0347 - mae: 0.1055\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0346 - mae: 0.1056\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.0344 - mae: 0.1057\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0343 - mae: 0.1058\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0342 - mae: 0.1060\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 281ms/step - loss: 0.0341 - mae: 0.1061 - val_loss: 0.0274 - val_mae: 0.1093\n",
      "\n",
      "{'loss': [0.03173340857028961], 'mae': [0.10842398554086685], 'val_loss': [0.02744743973016739], 'val_mae': [0.10929302871227264]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 14s/step - loss: 0.0295 - mae: 0.0726\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.3093 - mae: 0.3157\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.3417 - mae: 0.3510\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.3351 - mae: 0.3475\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.3208 - mae: 0.3357\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 788ms/step - loss: 0.3113 - mae: 0.3278 - val_loss: 0.0622 - val_mae: 0.1267\n",
      "\n",
      "{'loss': [0.2639254629611969], 'mae': [0.2884395718574524], 'val_loss': [0.062156617641448975], 'val_mae': [0.12674924731254578]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:15\u001b[0m 13s/step - loss: 0.0173 - mae: 0.0546\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0311 - mae: 0.0758 \n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0313 - mae: 0.0760\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0317 - mae: 0.0764\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0311 - mae: 0.0754\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 0.0310 - mae: 0.0750\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 0.0316 - mae: 0.0756\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - loss: 0.0317 - mae: 0.0756\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0321 - mae: 0.0760 \n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0330 - mae: 0.0773\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0335 - mae: 0.0781\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0347 - mae: 0.0801\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0353 - mae: 0.0815\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0357 - mae: 0.0826\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0358 - mae: 0.0829\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0359 - mae: 0.0837\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0362 - mae: 0.0845\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0364 - mae: 0.0854\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0365 - mae: 0.0858\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0366 - mae: 0.0862\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0366 - mae: 0.0866\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0367 - mae: 0.0870\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0367 - mae: 0.0873\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0367 - mae: 0.0876\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0367 - mae: 0.0881\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0367 - mae: 0.0883\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0366 - mae: 0.0885\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0366 - mae: 0.0888\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0366 - mae: 0.0890\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 141ms/step - loss: 0.0365 - mae: 0.0894 - val_loss: 0.0438 - val_mae: 0.1248\n",
      "\n",
      "{'loss': [0.035490214824676514], 'mae': [0.09778684377670288], 'val_loss': [0.043774500489234924], 'val_mae': [0.1248142197728157]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:53\u001b[0m 12s/step - loss: 0.0569 - mae: 0.1006\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0729 - mae: 0.1699 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0669 - mae: 0.1609\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0642 - mae: 0.1554\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0610 - mae: 0.1469\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0595 - mae: 0.1432\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0577 - mae: 0.1376\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0559 - mae: 0.1337\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0551 - mae: 0.1324\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0544 - mae: 0.1314\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0537 - mae: 0.1306\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0530 - mae: 0.1299\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0517 - mae: 0.1284\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0511 - mae: 0.1278\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0503 - mae: 0.1269\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0495 - mae: 0.1261\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0491 - mae: 0.1257\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0484 - mae: 0.1249\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0480 - mae: 0.1246\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0473 - mae: 0.1238\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0470 - mae: 0.1234\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0463 - mae: 0.1226\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0460 - mae: 0.1221\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0456 - mae: 0.1217\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0450 - mae: 0.1208\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0444 - mae: 0.1199\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0441 - mae: 0.1195\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 128ms/step - loss: 0.0438 - mae: 0.1190 - val_loss: 0.0178 - val_mae: 0.0707\n",
      "\n",
      "{'loss': [0.03223087266087532], 'mae': [0.1019536629319191], 'val_loss': [0.017822040244936943], 'val_mae': [0.07069277763366699]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 12s/step - loss: 0.0180 - mae: 0.0485\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 62.1846 - mae: 3.8593\n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 69.0928 - mae: 4.2893\n",
      "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 67.3681 - mae: 4.1901\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 63.8486 - mae: 3.9820\n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 60.1219 - mae: 3.7607\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 56.6145 - mae: 3.5516\n",
      "\u001b[1m 8/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 53.4292 - mae: 3.3615\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 50.5702 - mae: 3.1918\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 48.0481 - mae: 3.0418\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 360ms/step - loss: 45.9845 - mae: 2.9191 - val_loss: 0.0933 - val_mae: 0.2167\n",
      "\n",
      "{'loss': [25.348447799682617], 'mae': [1.6918509006500244], 'val_loss': [0.09333815425634384], 'val_mae': [0.21671760082244873]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:52\u001b[0m 12s/step - loss: 0.0373 - mae: 0.0573\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0418 - mae: 0.0757 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0394 - mae: 0.0740\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0371 - mae: 0.0716\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0369 - mae: 0.0717\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0367 - mae: 0.0726\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0366 - mae: 0.0730\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0365 - mae: 0.0732\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0366 - mae: 0.0737\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0368 - mae: 0.0742\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0368 - mae: 0.0745\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0368 - mae: 0.0752\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0367 - mae: 0.0758\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0367 - mae: 0.0761\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0367 - mae: 0.0764\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0367 - mae: 0.0770\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0366 - mae: 0.0772\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0365 - mae: 0.0773\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0364 - mae: 0.0775\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0363 - mae: 0.0780\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0362 - mae: 0.0785\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0361 - mae: 0.0790\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0361 - mae: 0.0795\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0361 - mae: 0.0798\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0360 - mae: 0.0800\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0360 - mae: 0.0802\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0360 - mae: 0.0805\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0360 - mae: 0.0810\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 125ms/step - loss: 0.0360 - mae: 0.0813 - val_loss: 0.0452 - val_mae: 0.1239\n",
      "\n",
      "{'loss': [0.03560344874858856], 'mae': [0.09051641076803207], 'val_loss': [0.045248452574014664], 'val_mae': [0.12392698973417282]}\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:45\u001b[0m 12s/step - loss: 0.0165 - mae: 0.0371\n",
      "\u001b[1m 2/20\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - loss: 0.0176 - mae: 0.0422\n",
      "\u001b[1m 3/20\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 198ms/step - loss: 0.0231 - mae: 0.0530\n",
      "\u001b[1m 4/20\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 204ms/step - loss: 0.0270 - mae: 0.0601\n",
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 203ms/step - loss: 0.0299 - mae: 0.0655\n",
      "\u001b[1m 6/20\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 0.0317 - mae: 0.0693\n",
      "\u001b[1m 7/20\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.0327 - mae: 0.0720\n",
      "\u001b[1m 8/20\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 0.0334 - mae: 0.0745\n",
      "\u001b[1m 9/20\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 0.0341 - mae: 0.0768\n",
      "\u001b[1m10/20\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - loss: 0.0347 - mae: 0.0789\n",
      "\u001b[1m11/20\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - loss: 0.0351 - mae: 0.0808\n",
      "\u001b[1m12/20\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - loss: 0.0354 - mae: 0.0824\n",
      "\u001b[1m13/20\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - loss: 0.0356 - mae: 0.0837\n",
      "\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - loss: 0.0357 - mae: 0.0850\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0358 - mae: 0.0863\n",
      "\u001b[1m16/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0358 - mae: 0.0873\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.0359 - mae: 0.0884\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0358 - mae: 0.0893\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0358 - mae: 0.0901\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.0358 - mae: 0.0909\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 263ms/step - loss: 0.0357 - mae: 0.0916 - val_loss: 0.0409 - val_mae: 0.1294\n",
      "\n",
      "{'loss': [0.035073935985565186], 'mae': [0.10581854730844498], 'val_loss': [0.040909577161073685], 'val_mae': [0.12944190204143524]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:13\u001b[0m 13s/step - loss: 0.0503 - mae: 0.0771\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0591 - mae: 0.1404 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0580 - mae: 0.1412\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0546 - mae: 0.1342\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0540 - mae: 0.1321\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0533 - mae: 0.1301\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0530 - mae: 0.1288\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0524 - mae: 0.1267\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0520 - mae: 0.1261\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0517 - mae: 0.1257\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0513 - mae: 0.1255\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0505 - mae: 0.1253\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0496 - mae: 0.1249\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0488 - mae: 0.1243\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0479 - mae: 0.1236\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0475 - mae: 0.1232\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0467 - mae: 0.1222\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0463 - mae: 0.1217\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0459 - mae: 0.1213\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0451 - mae: 0.1202\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0447 - mae: 0.1196\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0439 - mae: 0.1185\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0432 - mae: 0.1175\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0429 - mae: 0.1170\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0423 - mae: 0.1160\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0421 - mae: 0.1155\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 128ms/step - loss: 0.0415 - mae: 0.1146 - val_loss: 0.0219 - val_mae: 0.0876\n",
      "\n",
      "{'loss': [0.031058838590979576], 'mae': [0.0968799740076065], 'val_loss': [0.02189144678413868], 'val_mae': [0.08762123435735703]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 13s/step - loss: 0.0428 - mae: 0.0754\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.2249 - mae: 0.2710\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.2442 - mae: 0.2972\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.2385 - mae: 0.2936\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.2286 - mae: 0.2844\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 623ms/step - loss: 0.2220 - mae: 0.2783 - val_loss: 0.0623 - val_mae: 0.1275\n",
      "\n",
      "{'loss': [0.1891777217388153], 'mae': [0.24750187993049622], 'val_loss': [0.0623374804854393], 'val_mae': [0.1274847686290741]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19:37\u001b[0m 30s/step - loss: 0.0306 - mae: 0.0842\n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0366 - mae: 0.1164  \n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0373 - mae: 0.1204\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0371 - mae: 0.1217\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - loss: 0.0355 - mae: 0.1200\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0348 - mae: 0.1182\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - loss: 0.0339 - mae: 0.1157\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.0333 - mae: 0.1137\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0321 - mae: 0.1093 \n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0309 - mae: 0.1056\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0305 - mae: 0.1041\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0301 - mae: 0.1029\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0299 - mae: 0.1019\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0296 - mae: 0.1010\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0293 - mae: 0.1001\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0290 - mae: 0.0992\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0287 - mae: 0.0983\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0285 - mae: 0.0976\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0283 - mae: 0.0969\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0282 - mae: 0.0964\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0279 - mae: 0.0956\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0278 - mae: 0.0953\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0277 - mae: 0.0950\n",
      "\u001b[1m29/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0276 - mae: 0.0947\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0274 - mae: 0.0944\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0272 - mae: 0.0938\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0271 - mae: 0.0935\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0270 - mae: 0.0933\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0268 - mae: 0.0928\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0267 - mae: 0.0925\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0266 - mae: 0.0923\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0265 - mae: 0.0920\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0264 - mae: 0.0918\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 149ms/step - loss: 0.0263 - mae: 0.0916 - val_loss: 0.0221 - val_mae: 0.0716\n",
      "\n",
      "{'loss': [0.022404061630368233], 'mae': [0.08238958567380905], 'val_loss': [0.022137869149446487], 'val_mae': [0.07156140357255936]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:51\u001b[0m 12s/step - loss: 0.0331 - mae: 0.0870\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 2.1180 - mae: 0.7817 \n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - loss: 2.3497 - mae: 0.8617\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 2.2928 - mae: 0.8440 \n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 2.1753 - mae: 0.8059\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - loss: 2.0516 - mae: 0.7669\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 1.9348 - mae: 0.7295\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 1.8282 - mae: 0.6947\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - loss: 1.7324 - mae: 0.6633\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - loss: 1.6468 - mae: 0.6354\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 1.5799 - mae: 0.6159\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 1.5179 - mae: 0.5972\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 1.4082 - mae: 0.5637 \n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 1.3597 - mae: 0.5488\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 1.3147 - mae: 0.5348\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 1.2729 - mae: 0.5218\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 1.2340 - mae: 0.5097\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 1.1978 - mae: 0.4985 \n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 1.1322 - mae: 0.4780\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 1.1026 - mae: 0.4689\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 1.0746 - mae: 0.4602\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 1.0484 - mae: 0.4521\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 1.0003 - mae: 0.4375\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.9781 - mae: 0.4306\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.9570 - mae: 0.4240\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.9180 - mae: 0.4118\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.8999 - mae: 0.4061\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.8826 - mae: 0.4006\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.8660 - mae: 0.3953\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.8502 - mae: 0.3902\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.8350 - mae: 0.3853\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.8204 - mae: 0.3805\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.8065 - mae: 0.3758\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.7802 - mae: 0.3671\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.7679 - mae: 0.3630\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 156ms/step - loss: 0.7562 - mae: 0.3591 - val_loss: 0.0569 - val_mae: 0.1091\n",
      "\n",
      "{'loss': [0.2887556850910187], 'mae': [0.2033073902130127], 'val_loss': [0.05694754421710968], 'val_mae': [0.10905402153730392]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 12s/step - loss: 0.0447 - mae: 0.0872\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - loss: 0.0428 - mae: 0.1059\n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - loss: 0.0408 - mae: 0.1105\n",
      "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 254ms/step - loss: 0.0392 - mae: 0.1112\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - loss: 0.0381 - mae: 0.1104\n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 277ms/step - loss: 0.0376 - mae: 0.1100\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 0.0373 - mae: 0.1101\n",
      "\u001b[1m 8/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - loss: 0.0369 - mae: 0.1106\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 0.0364 - mae: 0.1109\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - loss: 0.0360 - mae: 0.1111\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 467ms/step - loss: 0.0357 - mae: 0.1112 - val_loss: 0.0339 - val_mae: 0.0889\n",
      "\n",
      "{'loss': [0.032290831208229065], 'mae': [0.11241015046834946], 'val_loss': [0.03393540531396866], 'val_mae': [0.08886315673589706]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:41\u001b[0m 12s/step - loss: 0.0161 - mae: 0.0491\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0192 - mae: 0.0663 \n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0208 - mae: 0.0740\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.0236 - mae: 0.0805\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0249 - mae: 0.0842\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0254 - mae: 0.0866\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0254 - mae: 0.0885\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - loss: 0.0252 - mae: 0.0884\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0249 - mae: 0.0880 \n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0248 - mae: 0.0877\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0246 - mae: 0.0875\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0245 - mae: 0.0873\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0244 - mae: 0.0873\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0243 - mae: 0.0874\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0242 - mae: 0.0875\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0241 - mae: 0.0875\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0239 - mae: 0.0874\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0238 - mae: 0.0872\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0238 - mae: 0.0872\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0238 - mae: 0.0871\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0238 - mae: 0.0871\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0239 - mae: 0.0872\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0239 - mae: 0.0873\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0240 - mae: 0.0875\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0240 - mae: 0.0876\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0241 - mae: 0.0876\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0241 - mae: 0.0877\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0241 - mae: 0.0877\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0241 - mae: 0.0876\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0241 - mae: 0.0876\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0241 - mae: 0.0875\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0241 - mae: 0.0875\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 168ms/step - loss: 0.0241 - mae: 0.0874 - val_loss: 0.0158 - val_mae: 0.0819\n",
      "\n",
      "{'loss': [0.023984668776392937], 'mae': [0.08576104044914246], 'val_loss': [0.015799222514033318], 'val_mae': [0.0819486454129219]}\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:21\u001b[0m 14s/step - loss: 0.0713 - mae: 0.1235\n",
      "\u001b[1m 2/20\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0581 - mae: 0.1086 \n",
      "\u001b[1m 3/20\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0523 - mae: 0.1040\n",
      "\u001b[1m 4/20\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - loss: 0.0493 - mae: 0.1035\n",
      "\u001b[1m 5/20\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0475 - mae: 0.1046\n",
      "\u001b[1m 6/20\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0461 - mae: 0.1062\n",
      "\u001b[1m 7/20\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0452 - mae: 0.1081\n",
      "\u001b[1m 8/20\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0444 - mae: 0.1098 \n",
      "\u001b[1m 9/20\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0437 - mae: 0.1111\n",
      "\u001b[1m10/20\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0429 - mae: 0.1118\n",
      "\u001b[1m11/20\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0421 - mae: 0.1122\n",
      "\u001b[1m12/20\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0413 - mae: 0.1123\n",
      "\u001b[1m13/20\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0407 - mae: 0.1121\n",
      "\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0400 - mae: 0.1118\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0394 - mae: 0.1112\n",
      "\u001b[1m16/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0388 - mae: 0.1106\n",
      "\u001b[1m17/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0383 - mae: 0.1100\n",
      "\u001b[1m18/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0377 - mae: 0.1094\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0373 - mae: 0.1089\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0369 - mae: 0.1085\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 259ms/step - loss: 0.0365 - mae: 0.1080 - val_loss: 0.0256 - val_mae: 0.0878\n",
      "\n",
      "{'loss': [0.02911909855902195], 'mae': [0.09955498576164246], 'val_loss': [0.02557320147752762], 'val_mae': [0.08780425041913986]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:13\u001b[0m 16s/step - loss: 0.0627 - mae: 0.1095\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0561 - mae: 0.1085  \n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0509 - mae: 0.1084\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0477 - mae: 0.1099\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0461 - mae: 0.1118\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - loss: 0.0444 - mae: 0.1126\n",
      "\u001b[1m 7/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 133ms/step - loss: 0.0431 - mae: 0.1130\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - loss: 0.0422 - mae: 0.1132\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 138ms/step - loss: 0.0414 - mae: 0.1131\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 136ms/step - loss: 0.0406 - mae: 0.1128\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - loss: 0.0398 - mae: 0.1125\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - loss: 0.0391 - mae: 0.1122\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - loss: 0.0384 - mae: 0.1117\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - loss: 0.0378 - mae: 0.1111\n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - loss: 0.0366 - mae: 0.1097\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - loss: 0.0361 - mae: 0.1090\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - loss: 0.0356 - mae: 0.1084\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - loss: 0.0351 - mae: 0.1077\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - loss: 0.0347 - mae: 0.1070\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0339 - mae: 0.1058\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0332 - mae: 0.1045\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0326 - mae: 0.1034\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0323 - mae: 0.1029 \n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0320 - mae: 0.1024\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0316 - mae: 0.1016\n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0313 - mae: 0.1012\n",
      "\u001b[1m33/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0310 - mae: 0.1006\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0306 - mae: 0.0999\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0303 - mae: 0.0994\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0300 - mae: 0.0989\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 149ms/step - loss: 0.0297 - mae: 0.0985 - val_loss: 0.0164 - val_mae: 0.0677\n",
      "\n",
      "{'loss': [0.024879738688468933], 'mae': [0.0906778872013092], 'val_loss': [0.016413124278187752], 'val_mae': [0.06769510358572006]}\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 14s/step - loss: 0.0383 - mae: 0.0763\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0360 - mae: 0.0747\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0354 - mae: 0.0754\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 0.0357 - mae: 0.0774\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - loss: 0.0358 - mae: 0.0792\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 728ms/step - loss: 0.0359 - mae: 0.0804 - val_loss: 0.0454 - val_mae: 0.1189\n",
      "\n",
      "{'loss': [0.036255668848752975], 'mae': [0.08631730824708939], 'val_loss': [0.04542277380824089], 'val_mae': [0.11893089860677719]}\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:47\u001b[0m 14s/step - loss: 0.0278 - mae: 0.0651\n",
      "\u001b[1m 2/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0265 - mae: 0.0686 \n",
      "\u001b[1m 3/40\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0316 - mae: 0.0792\n",
      "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - loss: 0.0333 - mae: 0.0864\n",
      "\u001b[1m 5/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0337 - mae: 0.0917\n",
      "\u001b[1m 6/40\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - loss: 0.0342 - mae: 0.0965\n",
      "\u001b[1m 8/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 0.0342 - mae: 0.1027\n",
      "\u001b[1m 9/40\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0343 - mae: 0.1048\n",
      "\u001b[1m10/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 0.0343 - mae: 0.1063\n",
      "\u001b[1m11/40\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0341 - mae: 0.1072\n",
      "\u001b[1m12/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - loss: 0.0338 - mae: 0.1076\n",
      "\u001b[1m13/40\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 0.0336 - mae: 0.1079\n",
      "\u001b[1m14/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - loss: 0.0336 - mae: 0.1080\n",
      "\u001b[1m15/40\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - loss: 0.0334 - mae: 0.1079 \n",
      "\u001b[1m16/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 0.0332 - mae: 0.1076\n",
      "\u001b[1m17/40\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 0.0330 - mae: 0.1073\n",
      "\u001b[1m18/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 0.0328 - mae: 0.1070\n",
      "\u001b[1m19/40\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0326 - mae: 0.1066\n",
      "\u001b[1m20/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - loss: 0.0325 - mae: 0.1063\n",
      "\u001b[1m21/40\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - loss: 0.0322 - mae: 0.1059\n",
      "\u001b[1m22/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0320 - mae: 0.1056\n",
      "\u001b[1m23/40\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0319 - mae: 0.1053\n",
      "\u001b[1m24/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0317 - mae: 0.1050\n",
      "\u001b[1m25/40\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0315 - mae: 0.1048\n",
      "\u001b[1m26/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0313 - mae: 0.1045\n",
      "\u001b[1m27/40\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0311 - mae: 0.1042\n",
      "\u001b[1m28/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0309 - mae: 0.1039\n",
      "\u001b[1m30/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0305 - mae: 0.1033 \n",
      "\u001b[1m31/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0304 - mae: 0.1030\n",
      "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0302 - mae: 0.1027\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0299 - mae: 0.1021\n",
      "\u001b[1m35/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0298 - mae: 0.1019\n",
      "\u001b[1m36/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0296 - mae: 0.1016\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0295 - mae: 0.1015\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0294 - mae: 0.1013\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0293 - mae: 0.1011\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 169ms/step - loss: 0.0291 - mae: 0.1008 - val_loss: 0.0214 - val_mae: 0.0808\n",
      "\n",
      "{'loss': [0.02501358836889267], 'mae': [0.09411495178937912], 'val_loss': [0.021374883130192757], 'val_mae': [0.08081246167421341]}\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 13s/step - loss: 0.0157 - mae: 0.0402\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 274ms/step - loss: 0.0237 - mae: 0.0554\n",
      "\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - loss: 0.0259 - mae: 0.0634\n",
      "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 253ms/step - loss: 0.0287 - mae: 0.0718\n",
      "\u001b[1m 5/10\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 237ms/step - loss: 0.0301 - mae: 0.0780\n",
      "\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - loss: 0.0309 - mae: 0.0832\n",
      "\u001b[1m 7/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.0315 - mae: 0.0875\n",
      "\u001b[1m 8/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - loss: 0.0317 - mae: 0.0910\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 0.0319 - mae: 0.0938\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 0.0320 - mae: 0.0958\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 496ms/step - loss: 0.0320 - mae: 0.0975 - val_loss: 0.0327 - val_mae: 0.1063\n",
      "\n",
      "{'loss': [0.03252710774540901], 'mae': [0.11453865468502045], 'val_loss': [0.03270857036113739], 'val_mae': [0.10630270093679428]}\n",
      "100%|██████████| 100/100 [29:37<00:00, 17.78s/trial, best loss: 0.013066052459180355]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "algo = partial(tpe.suggest, n_startup_jobs=20)\n",
    "best = fmin(lstm_training, param_grid, algo=algo, max_evals=100, pass_expr_memo_ctrl=None, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'layer1_dropout': 0.4911564799700332, 'layer2_dropout': 0.39202428357047303, 'learning_rate': 0.004123660790480552, 'lstm_units_1': 64, 'lstm_units_2': 64, 'lstm_units_3': 128, 'validation_split': 0.15877338748046974}\n"
     ]
    }
   ],
   "source": [
    "best_hps = space_eval(param_grid, best)\n",
    "print(best_hps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
